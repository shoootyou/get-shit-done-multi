---
phase: 07-multi-platform-testing
plan: 03
type: execute
wave: 3
depends_on: [07-02]
files_modified:
  - scripts/analyze-test-results.js
  - scripts/generate-platform-matrix.js
  - .planning/phases/07-multi-platform-testing/07-VALIDATION-REPORT.md
  - .planning/phases/07-multi-platform-testing/07-PLATFORM-CAPABILITY-MATRIX.md
  - .planning/phases/07.1-fix-platform-issues/07.1-DISCOVERY.md
autonomous: true
must_haves:
  - "Test results analyzed and categorized by failure type"
  - "Failures triaged with P0 (blocking) vs P1 (non-blocking) severity"
  - "Validation report documents testing outcomes and success rate"
  - "Platform capability matrix documents features/tools supported per platform"
  - "Phase 7.1 gap closure plan created if P0 failures exist"
  - "Success metrics calculated: installations, commands working, regression pass rate"
---

# Phase 7, Plan 3: Analysis + Reporting

**Objective:** Analyze test results, triage failures, generate comprehensive validation report, and create Phase 7.1 gap closure plan if needed

## Context

This plan processes the testing results from Plan 2, categorizes failures, and determines next steps.

**From Context decisions:**
- Failure categories: Platform bug, Spec bug, Install bug, Test setup bug, Expected difference
- Severity levels: P0 (blocking) vs P1 (non-blocking)
- Create fix plans but don't execute yet (defer to Phase 7.1)
- 100% success threshold (all 29 commands on all 3 platforms)

**Success metrics to calculate:**
- Installation success rate (target: 87/87 = 100%)
- Command discoverability rate (target: 87/87 = 100%)
- Regression test pass rate (target: 18/18 = 100%)
- Overall phase success (target: 100%)

**Phase 7.1 trigger:** If any P0 failures exist, create Phase 7.1 gap closure plan. If only P1 failures or no failures, mark Phase 7 complete and proceed to Phase 8.

## Tasks

<task name="create-analysis-script" type="auto">
  <files>
    scripts/analyze-test-results.js
  </files>
  
  <action>
Create script to analyze test results, calculate metrics, triage failures.

**Create scripts/analyze-test-results.js:**

```javascript
#!/usr/bin/env node
const fs = require('fs');
const path = require('path');

function loadResults() {
  const resultsDir = path.join(__dirname, '..', 'test-environments');
  
  const files = {
    install: path.join(resultsDir, 'install-results.json'),
    regression: path.join(resultsDir, 'regression-results.json'),
    manual: path.join(resultsDir, 'test-results.json')
  };
  
  const results = {};
  
  for (const [key, file] of Object.entries(files)) {
    if (fs.existsSync(file)) {
      try {
        results[key] = JSON.parse(fs.readFileSync(file, 'utf8'));
      } catch (error) {
        console.warn(`‚ö†Ô∏è  Failed to load ${key} results: ${error.message}`);
        results[key] = null;
      }
    } else {
      console.warn(`‚ö†Ô∏è  ${key} results file not found: ${file}`);
      results[key] = null;
    }
  }
  
  return results;
}

function analyzeInstallResults(installResults) {
  if (!installResults || !Array.isArray(installResults)) {
    return {
      totalPlatforms: 0,
      successfulPlatforms: 0,
      totalInstallations: 0,
      successfulInstallations: 0,
      failures: []
    };
  }
  
  const expectedCommandsPerPlatform = 29;
  const failures = [];
  
  let totalInstallations = 0;
  let successfulInstallations = 0;
  let successfulPlatforms = 0;
  
  for (const result of installResults) {
    const installed = result.skillsGenerated || 0;
    totalInstallations += installed;
    
    if (result.success && installed === expectedCommandsPerPlatform) {
      successfulInstallations += installed;
      successfulPlatforms++;
    } else {
      failures.push({
        platform: result.platform,
        type: 'install',
        severity: 'P0',
        category: result.error ? 'Install bug' : 'Spec bug',
        description: result.error || `Only ${installed}/${expectedCommandsPerPlatform} commands installed`,
        commands: installed,
        errors: result.errors || []
      });
    }
  }
  
  return {
    totalPlatforms: installResults.length,
    successfulPlatforms,
    totalInstallations,
    successfulInstallations,
    expectedTotal: installResults.length * expectedCommandsPerPlatform,
    failures
  };
}

function analyzeRegressionResults(regressionResults) {
  if (!regressionResults || !Array.isArray(regressionResults)) {
    return {
      totalTests: 0,
      passed: 0,
      failed: 0,
      failures: []
    };
  }
  
  const failures = [];
  let passed = 0;
  
  for (const result of regressionResults) {
    if (result.success) {
      passed++;
    } else {
      failures.push({
        platform: result.platform,
        command: result.command,
        type: 'regression',
        severity: 'P0',
        category: 'Spec bug',
        description: result.error || 'Regression test failed',
        error: result.error
      });
    }
  }
  
  return {
    totalTests: regressionResults.length,
    passed,
    failed: regressionResults.length - passed,
    failures
  };
}

function analyzeManualResults(manualResults) {
  if (!manualResults) {
    return {
      platforms: [],
      totalFailures: 0,
      p0Failures: 0,
      p1Failures: 0,
      failures: []
    };
  }
  
  // Manual results may be single platform object or array
  const platforms = Array.isArray(manualResults) ? manualResults : [manualResults];
  
  const failures = [];
  let totalFailures = 0;
  let p0Failures = 0;
  let p1Failures = 0;
  
  for (const platform of platforms) {
    if (platform.failures && Array.isArray(platform.failures)) {
      for (const failure of platform.failures) {
        failures.push({
          platform: platform.platform,
          command: failure.command,
          type: 'manual',
          severity: failure.severity || 'P1',
          category: failure.category || 'Unknown',
          description: failure.error || failure.description,
          error: failure.error
        });
        
        totalFailures++;
        if (failure.severity === 'P0') {
          p0Failures++;
        } else {
          p1Failures++;
        }
      }
    }
  }
  
  return {
    platforms: platforms.map(p => p.platform),
    totalFailures,
    p0Failures,
    p1Failures,
    failures
  };
}

function categorizeFailures(allFailures) {
  const categories = {
    'Platform bug': [],
    'Spec bug': [],
    'Install bug': [],
    'Test setup bug': [],
    'Expected difference': []
  };
  
  for (const failure of allFailures) {
    const category = failure.category || 'Unknown';
    if (categories[category]) {
      categories[category].push(failure);
    } else {
      if (!categories['Unknown']) {
        categories['Unknown'] = [];
      }
      categories['Unknown'].push(failure);
    }
  }
  
  return categories;
}

function calculateMetrics(analysis) {
  const { install, regression, manual } = analysis;
  
  // Installation metrics
  const installRate = install.expectedTotal > 0
    ? (install.successfulInstallations / install.expectedTotal * 100).toFixed(1)
    : 0;
  
  // Regression metrics
  const regressionRate = regression.totalTests > 0
    ? (regression.passed / regression.totalTests * 100).toFixed(1)
    : 0;
  
  // Overall metrics
  const totalFailures = install.failures.length + regression.failures.length + manual.totalFailures;
  const p0Failures = install.failures.filter(f => f.severity === 'P0').length +
                     regression.failures.filter(f => f.severity === 'P0').length +
                     manual.p0Failures;
  
  const phaseSuccess = totalFailures === 0;
  const needsGapClosure = p0Failures > 0;
  
  return {
    installRate,
    regressionRate,
    totalFailures,
    p0Failures,
    p1Failures: totalFailures - p0Failures,
    phaseSuccess,
    needsGapClosure
  };
}

function generateReport(analysis, metrics) {
  const lines = [];
  
  lines.push('# Phase 7: Multi-Platform Testing - Analysis Report');
  lines.push('');
  lines.push(`**Generated:** ${new Date().toISOString()}`);
  lines.push('');
  
  // Overall metrics
  lines.push('## Overall Metrics');
  lines.push('');
  lines.push(`- **Installation success rate:** ${metrics.installRate}% (${analysis.install.successfulInstallations}/${analysis.install.expectedTotal})`);
  lines.push(`- **Regression pass rate:** ${metrics.regressionRate}% (${analysis.regression.passed}/${analysis.regression.totalTests})`);
  lines.push(`- **Total failures:** ${metrics.totalFailures}`);
  lines.push(`- **P0 (blocking) failures:** ${metrics.p0Failures}`);
  lines.push(`- **P1 (non-blocking) failures:** ${metrics.p1Failures}`);
  lines.push(`- **Phase success:** ${metrics.phaseSuccess ? '‚úÖ PASS' : '‚ùå FAIL'}`);
  lines.push(`- **Needs gap closure:** ${metrics.needsGapClosure ? '‚ö†Ô∏è  YES (Phase 7.1)' : '‚úÖ NO'}`);
  lines.push('');
  
  // Installation details
  lines.push('## Installation Results');
  lines.push('');
  lines.push(`Platforms tested: ${analysis.install.totalPlatforms}`);
  lines.push(`Successful platforms: ${analysis.install.successfulPlatforms}/${analysis.install.totalPlatforms}`);
  lines.push('');
  
  if (analysis.install.failures.length > 0) {
    lines.push('### Installation Failures');
    lines.push('');
    for (const failure of analysis.install.failures) {
      lines.push(`- **${failure.platform}** (${failure.severity}): ${failure.description}`);
      if (failure.errors && failure.errors.length > 0) {
        failure.errors.forEach(err => lines.push(`  - ${err}`));
      }
    }
    lines.push('');
  }
  
  // Regression details
  lines.push('## Regression Results');
  lines.push('');
  lines.push(`Tests run: ${analysis.regression.totalTests}`);
  lines.push(`Passed: ${analysis.regression.passed}`);
  lines.push(`Failed: ${analysis.regression.failed}`);
  lines.push('');
  
  if (analysis.regression.failures.length > 0) {
    lines.push('### Regression Failures');
    lines.push('');
    for (const failure of analysis.regression.failures) {
      lines.push(`- **${failure.platform}/${failure.command}** (${failure.severity}): ${failure.description}`);
    }
    lines.push('');
  }
  
  // Manual testing details
  if (analysis.manual.totalFailures > 0) {
    lines.push('## Manual Testing Failures');
    lines.push('');
    lines.push(`Platforms: ${analysis.manual.platforms.join(', ')}`);
    lines.push(`Total failures: ${analysis.manual.totalFailures}`);
    lines.push(`P0 failures: ${analysis.manual.p0Failures}`);
    lines.push(`P1 failures: ${analysis.manual.p1Failures}`);
    lines.push('');
    
    for (const failure of analysis.manual.failures) {
      lines.push(`- **${failure.platform}/${failure.command}** (${failure.severity}, ${failure.category}): ${failure.description}`);
    }
    lines.push('');
  }
  
  // Categorized failures
  const allFailures = [
    ...analysis.install.failures,
    ...analysis.regression.failures,
    ...analysis.manual.failures
  ];
  
  if (allFailures.length > 0) {
    const categories = categorizeFailures(allFailures);
    
    lines.push('## Failures by Category');
    lines.push('');
    
    for (const [category, failures] of Object.entries(categories)) {
      if (failures.length > 0) {
        lines.push(`### ${category} (${failures.length})`);
        lines.push('');
        for (const failure of failures) {
          const location = failure.command 
            ? `${failure.platform}/${failure.command}`
            : failure.platform;
          lines.push(`- **${location}** (${failure.severity}): ${failure.description}`);
        }
        lines.push('');
      }
    }
  }
  
  // Next steps
  lines.push('## Next Steps');
  lines.push('');
  
  if (metrics.needsGapClosure) {
    lines.push(`1. Create Phase 7.1 gap closure plan to address ${metrics.p0Failures} P0 failures`);
    lines.push('2. Execute Phase 7.1 to fix blocking issues');
    lines.push('3. Re-run testing to verify fixes');
    if (metrics.p1Failures > 0) {
      lines.push(`4. Consider addressing ${metrics.p1Failures} P1 failures in Phase 7.1 or defer to Phase 8`);
    }
  } else if (metrics.totalFailures > 0) {
    lines.push(`1. Review ${metrics.p1Failures} P1 failures`);
    lines.push('2. Decide: Fix in Phase 7.1 or defer to Phase 8 (documentation)');
    lines.push('3. If defer, proceed to Phase 8');
  } else {
    lines.push('1. ‚úÖ Phase 7 complete - all tests passing');
    lines.push('2. Proceed to Phase 8: Documentation & Release');
  }
  lines.push('');
  
  return lines.join('\n');
}

async function main() {
  console.log('üìä Analyzing test results...\n');
  
  // Load results
  const results = loadResults();
  
  // Analyze each result type
  const analysis = {
    install: analyzeInstallResults(results.install),
    regression: analyzeRegressionResults(results.regression),
    manual: analyzeManualResults(results.manual)
  };
  
  // Calculate metrics
  const metrics = calculateMetrics(analysis);
  
  // Generate report
  const report = generateReport(analysis, metrics);
  
  // Write report
  const reportPath = path.join(__dirname, '..', '.planning', 'phases', '07-multi-platform-testing', '07-ANALYSIS-REPORT.md');
  fs.writeFileSync(reportPath, report);
  
  console.log('üìÑ Analysis report written to:');
  console.log(`   ${reportPath}`);
  console.log('');
  
  // Console summary
  console.log('='.repeat(60));
  console.log('Test Analysis Summary');
  console.log('='.repeat(60));
  console.log(`Installation rate: ${metrics.installRate}%`);
  console.log(`Regression rate: ${metrics.regressionRate}%`);
  console.log(`Total failures: ${metrics.totalFailures}`);
  console.log(`P0 failures: ${metrics.p0Failures}`);
  console.log(`P1 failures: ${metrics.p1Failures}`);
  console.log(`Phase success: ${metrics.phaseSuccess ? '‚úÖ PASS' : '‚ùå FAIL'}`);
  console.log(`Needs Phase 7.1: ${metrics.needsGapClosure ? '‚ö†Ô∏è  YES' : '‚úÖ NO'}`);
  console.log('='.repeat(60));
  
  // Exit code
  if (!metrics.phaseSuccess) {
    console.log('\n‚ö†Ô∏è  Phase 7 has failures - gap closure recommended');
    process.exit(1);
  }
  
  console.log('\n‚úÖ Phase 7 analysis complete!');
}

if (require.main === module) {
  main().catch(err => {
    console.error('‚ùå Analysis error:', err);
    process.exit(1);
  });
}

module.exports = {
  loadResults,
  analyzeInstallResults,
  analyzeRegressionResults,
  analyzeManualResults,
  calculateMetrics,
  generateReport
};
```
  </action>
  
  <verify>
```bash
# Verify script exists
ls -la scripts/analyze-test-results.js

# Run analysis (requires test results from Plan 2)
node scripts/analyze-test-results.js

# Verify report generated
ls -la .planning/phases/07-multi-platform-testing/07-ANALYSIS-REPORT.md
cat .planning/phases/07-multi-platform-testing/07-ANALYSIS-REPORT.md
```
  </verify>
  
  <done>
- [x] scripts/analyze-test-results.js analyzes all test result files
- [x] Script calculates installation rate, regression rate, failure counts
- [x] Script categorizes failures by type (Platform/Spec/Install/Test/Expected)
- [x] Script triages failures by severity (P0 vs P1)
- [x] Script generates comprehensive analysis report in markdown
- [x] Script determines if Phase 7.1 gap closure needed
  </done>
</task>

<task name="generate-platform-capability-matrix" type="auto">
  <files>
    scripts/generate-platform-matrix.js
    .planning/phases/07-multi-platform-testing/07-PLATFORM-CAPABILITY-MATRIX.md
  </files>
  
  <action>
Generate platform capability matrix documenting which features work on which platforms (PLAT-11).

**1. Create scripts/generate-platform-matrix.js:**

```javascript
#!/usr/bin/env node
const fs = require('fs');
const path = require('path');

function loadTestResults() {
  const resultsDir = path.join(__dirname, '..', 'test-environments');
  
  const results = {
    install: loadJSON(path.join(resultsDir, 'install-results.json')),
    regression: loadJSON(path.join(resultsDir, 'regression-results.json')),
    toolMapping: loadJSON(path.join(resultsDir, 'tool-mapping-results.json')),
    manual: loadJSON(path.join(resultsDir, 'test-results.json'))
  };
  
  return results;
}

function loadJSON(filePath) {
  if (fs.existsSync(filePath)) {
    try {
      return JSON.parse(fs.readFileSync(filePath, 'utf8'));
    } catch (error) {
      console.warn(`Failed to load ${filePath}:`, error.message);
      return null;
    }
  }
  return null;
}

function generateCapabilityMatrix(results) {
  const matrix = {
    claude: {
      name: 'Claude Code',
      installation: 'Supported',
      commandCount: 29,
      tools: ['view', 'edit', 'create', 'bash', 'task'],
      features: {
        'Multi-file editing': true,
        'Command autocomplete': true,
        'Agent spawning': true,
        'Checkpoint support': true,
        'Parallel execution': true,
        'Platform conditionals': true,
        'YAML frontmatter': true,
        'Metadata fields': true
      },
      limitations: [],
      status: 'Primary platform'
    },
    copilot: {
      name: 'GitHub Copilot CLI',
      installation: 'Supported',
      commandCount: 29,
      tools: ['read_file', 'edit_file', 'create_file', 'execute_command', 'delegate_task'],
      features: {
        'Multi-file editing': true,
        'Command autocomplete': true,
        'Agent spawning': true,
        'Checkpoint support': true,
        'Parallel execution': true,
        'Platform conditionals': true,
        'YAML frontmatter': true,
        'Metadata fields': false // May have limitations
      },
      limitations: [
        'Tool names differ from Claude (mapped automatically)',
        'May not support all metadata fields'
      ],
      status: 'Full support with adaptations'
    },
    codex: {
      name: 'Codex CLI',
      installation: 'Supported',
      commandCount: 29,
      tools: ['file.read', 'file.modify', 'file.create', 'shell.execute', 'agent.spawn'],
      features: {
        'Multi-file editing': true,
        'Command autocomplete': true,
        'Agent spawning': true,
        'Checkpoint support': true,
        'Parallel execution': true,
        'Platform conditionals': true,
        'YAML frontmatter': true,
        'Metadata fields': false // May have limitations
      },
      limitations: [
        'Tool names differ from Claude (mapped automatically)',
        'Invocation syntax differs ($ prefix)',
        'May not support all metadata fields'
      ],
      status: 'Full support with adaptations'
    }
  };
  
  // Update with actual test results if available
  if (results.install && Array.isArray(results.install)) {
    for (const platformResult of results.install) {
      const platform = platformResult.platform;
      if (matrix[platform]) {
        matrix[platform].commandCount = platformResult.skillsGenerated || 0;
        matrix[platform].installation = platformResult.success ? 'Verified' : 'Failed';
      }
    }
  }
  
  if (results.toolMapping && Array.isArray(results.toolMapping)) {
    for (const platformResult of results.toolMapping) {
      const platform = platformResult.platform;
      if (matrix[platform] && platformResult.contentRendering) {
        const renderRate = (platformResult.contentRendering.passed / platformResult.contentRendering.tested) * 100;
        matrix[platform].features['Platform conditionals'] = renderRate > 80;
      }
    }
  }
  
  return matrix;
}

function generateMatrixDocument(matrix) {
  const lines = [];
  
  lines.push('# Platform Capability Matrix');
  lines.push('');
  lines.push('**Generated:** ' + new Date().toISOString());
  lines.push('**Phase:** 07-multi-platform-testing');
  lines.push('');
  lines.push('## Overview');
  lines.push('');
  lines.push('This document details which GSD features and capabilities are supported on each platform.');
  lines.push('');
  
  // Summary table
  lines.push('## Platform Support Summary');
  lines.push('');
  lines.push('| Platform | Installation | Commands | Tools | Status |');
  lines.push('|----------|-------------|----------|-------|--------|');
  
  for (const [id, platform] of Object.entries(matrix)) {
    lines.push(`| ${platform.name} | ${platform.installation} | ${platform.commandCount}/29 | ${platform.tools.length} | ${platform.status} |`);
  }
  
  lines.push('');
  
  // Detailed breakdown per platform
  for (const [id, platform] of Object.entries(matrix)) {
    lines.push(`## ${platform.name}`);
    lines.push('');
    lines.push(`**Platform ID:** \`${id}\``);
    lines.push(`**Installation:** ${platform.installation}`);
    lines.push(`**Commands Available:** ${platform.commandCount}/29`);
    lines.push(`**Status:** ${platform.status}`);
    lines.push('');
    
    lines.push('### Tools');
    lines.push('');
    for (const tool of platform.tools) {
      lines.push(`- \`${tool}\``);
    }
    lines.push('');
    
    lines.push('### Features');
    lines.push('');
    for (const [feature, supported] of Object.entries(platform.features)) {
      const icon = supported ? '‚úÖ' : '‚ùå';
      lines.push(`- ${icon} ${feature}`);
    }
    lines.push('');
    
    if (platform.limitations.length > 0) {
      lines.push('### Limitations');
      lines.push('');
      for (const limitation of platform.limitations) {
        lines.push(`- ${limitation}`);
      }
      lines.push('');
    }
  }
  
  // Feature compatibility matrix
  lines.push('## Feature Compatibility Matrix');
  lines.push('');
  lines.push('| Feature | Claude | Copilot | Codex |');
  lines.push('|---------|--------|---------|-------|');
  
  const allFeatures = new Set();
  for (const platform of Object.values(matrix)) {
    Object.keys(platform.features).forEach(f => allFeatures.add(f));
  }
  
  for (const feature of allFeatures) {
    const claudeStatus = matrix.claude.features[feature] ? '‚úÖ' : '‚ùå';
    const copilotStatus = matrix.copilot.features[feature] ? '‚úÖ' : '‚ùå';
    const codexStatus = matrix.codex.features[feature] ? '‚úÖ' : '‚ùå';
    
    lines.push(`| ${feature} | ${claudeStatus} | ${copilotStatus} | ${codexStatus} |`);
  }
  
  lines.push('');
  
  // Tool mapping reference
  lines.push('## Tool Mapping Reference');
  lines.push('');
  lines.push('How Claude tools map to each platform:');
  lines.push('');
  lines.push('| Claude Tool | Copilot Equivalent | Codex Equivalent |');
  lines.push('|-------------|-------------------|------------------|');
  lines.push('| `view` | `read_file` | `file.read` |');
  lines.push('| `edit` | `edit_file` | `file.modify` |');
  lines.push('| `create` | `create_file` | `file.create` |');
  lines.push('| `bash` | `execute_command` | `shell.execute` |');
  lines.push('| `task` | `delegate_task` | `agent.spawn` |');
  lines.push('');
  
  // Command coverage
  lines.push('## Command Coverage');
  lines.push('');
  lines.push('All 29 GSD commands are available on all platforms:');
  lines.push('');
  
  const commands = [
    'gsd-new-project', 'gsd-execute-phase', 'gsd-new-milestone',
    'gsd-plan-phase', 'gsd-research-phase', 'gsd-debug', 'gsd-map-codebase',
    'gsd-help', 'gsd-progress', 'gsd-verify-work', 'gsd-discuss-phase',
    'gsd-pause-work', 'gsd-resume-work', 'gsd-add-phase', 'gsd-insert-phase',
    'gsd-remove-phase', 'gsd-add-todo', 'gsd-check-todos', 'gsd-complete-milestone',
    'gsd-audit-milestone', 'gsd-plan-milestone-gaps', 'gsd-archive-milestone',
    'gsd-restore-milestone', 'gsd-list-milestones', 'gsd-list-phase-assumptions',
    'gsd-verify-installation', 'gsd-whats-new', 'gsd-update'
  ];
  
  lines.push('**High complexity (3):**');
  lines.push('- gsd-new-project, gsd-execute-phase, gsd-new-milestone');
  lines.push('');
  lines.push('**Medium complexity (4):**');
  lines.push('- gsd-plan-phase, gsd-research-phase, gsd-debug, gsd-map-codebase');
  lines.push('');
  lines.push('**Simple commands (22):**');
  lines.push('- All other commands (utility, state management, information)');
  lines.push('');
  
  // Platform-specific invocation
  lines.push('## Platform-Specific Invocation');
  lines.push('');
  lines.push('### Claude Code');
  lines.push('- Type `/gsd-` and use autocomplete');
  lines.push('- Commands appear in slash command menu');
  lines.push('- Full context window available');
  lines.push('');
  lines.push('### GitHub Copilot CLI');
  lines.push('- Type command name and press Tab for autocomplete');
  lines.push('- Commands registered as Copilot skills');
  lines.push('- Tool mappings handled automatically');
  lines.push('');
  lines.push('### Codex CLI');
  lines.push('- Type `$gsd-` and use autocomplete');
  lines.push('- Commands available as Codex skills');
  lines.push('- Tool mappings handled automatically');
  lines.push('');
  
  // Notes
  lines.push('## Notes');
  lines.push('');
  lines.push('1. **Tool mapping is automatic** - Specs written with Claude tools are automatically adapted for each platform');
  lines.push('2. **Platform conditionals** - Specs can include platform-specific content using {{#isClaude}}, {{#isCopilot}}, {{#isCodex}}');
  lines.push('3. **Metadata limitations** - Some platforms may not support all YAML frontmatter fields; non-critical fields are omitted');
  lines.push('4. **Testing coverage** - All platforms tested with same 29 commands for consistency');
  lines.push('5. **Backward compatibility** - Legacy command format still works when specs are not available');
  lines.push('');
  
  lines.push('---');
  lines.push('');
  lines.push('*Matrix generated from Phase 7 testing results*');
  
  return lines.join('\n');
}

async function main() {
  console.log('üìä Generating Platform Capability Matrix\n');
  
  // Load test results
  const results = loadTestResults();
  
  // Generate capability matrix
  const matrix = generateCapabilityMatrix(results);
  
  // Generate markdown document
  const document = generateMatrixDocument(matrix);
  
  // Write to file
  const outputPath = path.join(__dirname, '..', '.planning', 'phases', '07-multi-platform-testing', '07-PLATFORM-CAPABILITY-MATRIX.md');
  fs.writeFileSync(outputPath, document);
  
  console.log('‚úÖ Platform capability matrix generated');
  console.log(`   ${outputPath}`);
  console.log('');
  
  // Summary
  console.log('='.repeat(60));
  console.log('Platform Support Summary');
  console.log('='.repeat(60));
  
  for (const [id, platform] of Object.entries(matrix)) {
    console.log(`\n${platform.name}:`);
    console.log(`  Installation: ${platform.installation}`);
    console.log(`  Commands: ${platform.commandCount}/29`);
    console.log(`  Tools: ${platform.tools.length}`);
    console.log(`  Status: ${platform.status}`);
  }
  
  console.log('\n‚úÖ Matrix generation complete!');
}

if (require.main === module) {
  main().catch(err => {
    console.error('‚ùå Generation error:', err);
    process.exit(1);
  });
}

module.exports = { generateCapabilityMatrix, generateMatrixDocument };
```

**2. Make script executable:**

```bash
chmod +x scripts/generate-platform-matrix.js
```
  </action>
  
  <verify>
```bash
# Verify script exists
ls -la scripts/generate-platform-matrix.js

# Run matrix generation (after test results available)
node scripts/generate-platform-matrix.js

# Verify matrix document created
cat .planning/phases/07-multi-platform-testing/07-PLATFORM-CAPABILITY-MATRIX.md
```
  </verify>
  
  <done>
- [x] scripts/generate-platform-matrix.js creates platform capability matrix
- [x] Matrix documents features supported per platform (PLAT-11)
- [x] Matrix includes tool mapping reference
- [x] Matrix includes command coverage breakdown
- [x] Matrix includes platform-specific invocation instructions
- [x] 07-PLATFORM-CAPABILITY-MATRIX.md generated with comprehensive details
  </done>
</task>

<task name="generate-validation-report" type="auto">
  <files>
    .planning/phases/07-multi-platform-testing/07-VALIDATION-REPORT.md
  </files>
  
  <action>
Generate comprehensive validation report documenting Phase 7 outcomes.

**Create 07-VALIDATION-REPORT.md:**

```markdown
# Phase 7: Multi-Platform Testing - Validation Report

**Phase:** 07-multi-platform-testing
**Status:** [Complete/In Progress/Needs Gap Closure]
**Generated:** [Timestamp]

## Executive Summary

Phase 7 tested installation and execution of all 29 GSD commands across 3 platforms (Claude Code, GitHub Copilot CLI, Codex CLI) with comprehensive regression testing.

**Key Metrics:**
- Installation success rate: [X]%
- Regression pass rate: [X]%
- Total failures: [X]
- P0 (blocking) failures: [X]
- P1 (non-blocking) failures: [X]

**Outcome:** [‚úÖ Phase Complete / ‚ö†Ô∏è Phase 7.1 Required / ‚ùå Critical Issues]

## Requirements Coverage

### Foundation & Schema
- [x] **FOUN-06:** Schema validation - Implemented via Jest test suite (TEST-03)

### Multi-Platform Support
- [ ] **PLAT-05:** Tool mapping verification - [Status]
- [ ] **PLAT-06:** Platform-specific content rendering - [Status]
- [ ] **PLAT-07:** Claude Code installation - [Status]
- [ ] **PLAT-08:** GitHub Copilot CLI installation - [Status]
- [ ] **PLAT-09:** Codex CLI installation - [Status]
- [ ] **PLAT-10:** Platform detection with fallbacks - [Status]
- [ ] **PLAT-11:** Platform capability matrix documentation - [Status]

### Testing & Validation
- [x] **TEST-01:** Jest spec parsing tests - Implemented (__tests__/spec-parsing.test.js)
- [x] **TEST-02:** Conditional rendering tests - Implemented (__tests__/conditional-rendering.test.js)
- [x] **TEST-03:** Frontmatter validation tests - Implemented (__tests__/frontmatter-validation.test.js)
- [x] **TEST-04:** Metadata generation tests - Implemented (__tests__/metadata-generation.test.js)
- [x] **TEST-05:** Platform integration tests - Implemented (__tests__/platform-integration.test.js)
- [ ] **TEST-06:** --all flag parallel installation - [Status]
- [ ] **TEST-07:** Legacy fallback when spec missing - [Status]
- [ ] **TEST-08:** Regression tests for 29 commands - [Status]
- [ ] **TEST-10:** YAML parser compatibility - [Status]

## Test Infrastructure

### Established
- ‚úÖ Test environment setup script (isolated directories per platform)
- ‚úÖ Test environment cleanup script
- ‚úÖ Jest configuration (CommonJS, 30s timeout, verbose output)
- ‚úÖ Jest test suite (5 files, TEST-01 to TEST-05)
- ‚úÖ Platform installation testing script (automated)
- ‚úÖ Platform command testing guide (manual)
- ‚úÖ Regression testing script (file structure validation)
- ‚úÖ Test result analysis script

### Dependencies Added
- jest@29.x - Testing framework
- execa@5.1.1 - Process execution (CommonJS compatible)
- strip-ansi@7.x - ANSI code removal for output comparison
- diff@5.x - Text difference generation
- p-map@4.x - Parallel execution with concurrency control
- tmp-promise@3.x - Temporary directory management
- which@3.x - Executable location

## Platform Testing Results

### GitHub Copilot CLI
**Installation:** [Status]
**Commands Installed:** [X/29]
**Commands Working:** [X/29]
**Key Issues:**
- [List any P0 or P1 failures]

### Claude Code
**Installation:** [Status]
**Commands Installed:** [X/29]
**Commands Working:** [X/29]
**Key Issues:**
- [List any P0 or P1 failures]

### Codex CLI
**Installation:** [Status]
**Commands Installed:** [X/29]
**Commands Working:** [X/29]
**Key Issues:**
- [List any P0 or P1 failures]

## Regression Testing

**Safe Commands Tested:** 6 (gsd-help, gsd-verify-installation, gsd-list-milestones, gsd-whats-new, gsd-list-phase-assumptions, gsd-check-todos)

**Results:**
- Total tests: [X] (6 commands √ó 3 platforms = 18 tests)
- Passed: [X]
- Failed: [X]

**Failures:**
[List any regression test failures]

## Failure Analysis

### By Category

**Platform bug:** [Count] failures
- [Description of platform-specific limitations]

**Spec bug:** [Count] failures
- [Description of spec migration issues]

**Install bug:** [Count] failures
- [Description of installation/generation issues]

**Test setup bug:** [Count] failures
- [Description of test environment issues]

**Expected difference:** [Count] differences
- [Description of intentional platform differences]

### By Severity

**P0 (Blocking):** [Count] failures
- Must be fixed before v1.9.1 release
- Triggers Phase 7.1 gap closure

**P1 (Non-blocking):** [Count] failures
- Can be deferred to Phase 7.1 or Phase 8
- Nice-to-have improvements

## Gaps and Next Steps

### If P0 Failures Exist

**Phase 7.1 Required:** Yes

**Scope:**
- Fix [X] P0 failures
- [Optional] Address [Y] P1 failures
- Re-run affected tests
- Verify fixes don't introduce regressions

**Plan structure:** [X] plans addressing:
1. [Category 1 fixes]
2. [Category 2 fixes]
3. Re-verification

### If Only P1 Failures or No Failures

**Phase 7.1 Required:** No

**Options for P1 failures:**
1. Fix in Phase 7.1 (recommended if quick wins)
2. Defer to Phase 8 (document as known issues)
3. Defer to v2 (if low priority)

**Next phase:** Phase 8 - Documentation & Release

## Success Criteria Met

Phase 7 goals:
- [x] Test environment infrastructure established
- [x] Jest test suite created and runs successfully
- [ ] Installation verified on all 3 platforms (target: 100%)
- [ ] Commands discoverable on all 3 platforms (target: 100%)
- [ ] Regression tests pass (target: 100%)
- [ ] Test results documented in structured format
- [ ] Failures triaged and categorized
- [ ] Gap closure plan created if needed

## Files Created

**Test Infrastructure:**
- test-environments/setup-test-env.js
- test-environments/cleanup-test-env.js
- test-environments/.gitignore

**Jest Test Suite:**
- jest.config.js
- __tests__/spec-parsing.test.js
- __tests__/conditional-rendering.test.js
- __tests__/frontmatter-validation.test.js
- __tests__/metadata-generation.test.js
- __tests__/platform-integration.test.js

**Testing Scripts:**
- scripts/test-platform-install.js
- scripts/test-platform-commands.js
- scripts/test-regression.js
- scripts/analyze-test-results.js

**Reports:**
- test-environments/install-results.json
- test-environments/regression-results.json
- test-environments/test-results.json (manual)
- .planning/phases/07-multi-platform-testing/07-ANALYSIS-REPORT.md
- .planning/phases/07-multi-platform-testing/07-VALIDATION-REPORT.md

## Conclusion

[Summary of phase outcome]

[Recommendation: Proceed to Phase 7.1 / Proceed to Phase 8 / Critical issues require attention]

---

*Validation report generated: [Timestamp]*
*Phase 7 execution: [Duration]*
```

**Note:** This template will be populated with actual results after test execution in Plan 2. The analysis script will generate 07-ANALYSIS-REPORT.md with raw data, and this validation report provides executive summary and strategic recommendations.
  </action>
  
  <verify>
```bash
# Verify validation report template exists
cat .planning/phases/07-multi-platform-testing/07-VALIDATION-REPORT.md

# After test execution, validation report should be populated with actual data
# Compare with analysis report
diff \
  .planning/phases/07-multi-platform-testing/07-ANALYSIS-REPORT.md \
  .planning/phases/07-multi-platform-testing/07-VALIDATION-REPORT.md
```
  </verify>
  
  <done>
- [x] 07-VALIDATION-REPORT.md template created with comprehensive structure
- [x] Report covers requirements, infrastructure, platform results, failures
- [x] Report includes gap analysis and next steps recommendations
- [x] Report documents all files created during Phase 7
- [x] Report provides executive summary and strategic guidance
  </done>
</task>

<task name="create-gap-closure-plan" type="auto">
  <files>
    .planning/phases/07.1-fix-platform-issues/07.1-DISCOVERY.md
  </files>
  
  <action>
Create Phase 7.1 gap closure plan template (if P0 failures exist).

**Create directory and template:**

```bash
mkdir -p .planning/phases/07.1-fix-platform-issues
```

**Create 07.1-DISCOVERY.md:**

```markdown
# Phase 7.1: Fix Platform Issues - Discovery

**Created:** [Timestamp]
**Source:** Phase 7 testing failures
**Status:** [To be planned / In progress / Complete]

## Background

Phase 7 multi-platform testing identified [X] P0 (blocking) failures that must be addressed before v1.9.1 release.

**Failure breakdown:**
- Platform bugs: [X]
- Spec bugs: [X]
- Install bugs: [X]
- Test setup bugs: [X]

**Source reports:**
- .planning/phases/07-multi-platform-testing/07-ANALYSIS-REPORT.md
- test-environments/install-results.json
- test-environments/regression-results.json
- test-environments/test-results.json

## P0 Failures to Address

### Platform Bugs

[List of platform-specific issues that require workarounds or platform fixes]

**Example:**
```
Issue: Claude Code doesn't support metadata fields in frontmatter
Impact: Commands fail to load on Claude platform
Platforms affected: Claude
Severity: P0
Root cause: Platform limitation
Fix approach: Remove metadata from Claude output (platform-specific conditional)
```

### Spec Bugs

[List of spec migration issues - incorrect YAML, missing fields, broken conditionals]

**Example:**
```
Issue: gsd-example has malformed YAML in frontmatter
Impact: Command fails to parse during installation
Platforms affected: All 3
Severity: P0
Root cause: Migration error in Phase 4
Fix approach: Correct YAML syntax in specs/skills/gsd-example/SKILL.md
```

### Install Bugs

[List of installation/generation issues - template system bugs, path issues]

**Example:**
```
Issue: generateSkillsFromSpecs() fails on Codex platform
Impact: No commands install on Codex
Platforms affected: Codex
Severity: P0
Root cause: Missing Codex adapter implementation
Fix approach: Complete Codex adapter in bin/lib/platform-adapters/codex.js
```

### Test Setup Bugs

[List of test environment issues that prevented valid testing]

**Example:**
```
Issue: Test environment missing git identity
Impact: Commands that commit fail during testing
Platforms affected: All 3
Severity: P0 (if blocking tests), P1 (if only affects test env)
Root cause: Test setup incomplete
Fix approach: Configure git identity in test-environments/setup-test-env.js
```

## P1 Failures (Optional)

[List of non-blocking failures that could be addressed in Phase 7.1 or deferred]

**Deferral criteria:**
- Quick win (< 30 min fix): Include in Phase 7.1
- Complex fix (> 1 hour): Defer to Phase 8 or v2
- Documentation-only issue: Defer to Phase 8

## Gap Closure Strategy

### Approach

1. **Group by root cause** - Cluster related failures
2. **Fix once, verify thrice** - Each fix should resolve failures across platforms where applicable
3. **Re-test comprehensively** - After fixes, re-run full test suite
4. **Track metrics** - Compare before/after failure counts

### Plan Structure

**Estimated plans:** [X] plans in [Y] waves

**Wave 1:** Spec bug fixes (parallel - independent fixes)
**Wave 2:** Install bug fixes (sequential - may depend on Wave 1)
**Wave 3:** Platform-specific workarounds (parallel - independent)
**Wave 4:** Re-verification (sequential - after all fixes)

### Success Criteria

Phase 7.1 complete when:
- [ ] All P0 failures from Phase 7 resolved
- [ ] Installation success rate: 100% (87/87 commands)
- [ ] Regression pass rate: 100% (18/18 tests)
- [ ] Re-run Phase 7 test suite - all pass
- [ ] No new failures introduced

## Tasks Preview

[Preliminary task breakdown - will be refined during planning]

**Plan 1: Spec Bug Fixes**
- Task 1: Fix YAML syntax errors in [X] specs
- Task 2: Add missing frontmatter fields to [Y] specs
- Task 3: Correct tool declarations in [Z] specs

**Plan 2: Install System Fixes**
- Task 1: Fix template rendering for [platform]
- Task 2: Complete platform adapter implementation
- Task 3: Fix path resolution in generateSkillsFromSpecs()

**Plan 3: Platform-Specific Workarounds**
- Task 1: Add Claude-specific conditionals to remove unsupported fields
- Task 2: Fix Copilot-specific tool formatting
- Task 3: Implement Codex-specific adaptations

**Plan 4: Re-Verification**
- Task 1: Re-run installation tests (automated)
- Task 2: Re-run regression tests (automated)
- Task 3: Spot-check manual tests (checkpoint)

## Timeline Estimate

**Duration:** [X] hours / [Y] plans

Based on:
- [X] P0 failures
- [Y] distinct root causes
- Average fix time per failure: [Z] minutes

## Notes

[Any additional context, caveats, or dependencies]

---

*Discovery document created from Phase 7 analysis*
*Next: `/gsd-plan-phase 07.1` to create executable plans*
```

**Note:** This template will only be used if Phase 7 analysis reveals P0 failures. If Phase 7 passes 100%, this file won't be needed and Phase 8 proceeds directly.
  </action>
  
  <verify>
```bash
# Verify directory created
ls -la .planning/phases/07.1-fix-platform-issues/

# Verify discovery template exists
cat .planning/phases/07.1-fix-platform-issues/07.1-DISCOVERY.md

# Conditional: Only populate if analysis shows P0 failures
node scripts/analyze-test-results.js | grep "Needs Phase 7.1"
```
  </verify>
  
  <done>
- [x] Phase 7.1 directory created: .planning/phases/07.1-fix-platform-issues/
- [x] 07.1-DISCOVERY.md template created with comprehensive structure
- [x] Template includes P0 failure categorization and fix approaches
- [x] Template provides gap closure strategy and plan preview
- [x] Template will be populated only if P0 failures exist
  </done>
</task>

## Verification

```bash
# 1. Run analysis script
node scripts/analyze-test-results.js

# 2. Generate platform capability matrix
node scripts/generate-platform-matrix.js

# 3. Verify reports generated
ls -la .planning/phases/07-multi-platform-testing/07-ANALYSIS-REPORT.md
ls -la .planning/phases/07-multi-platform-testing/07-VALIDATION-REPORT.md
ls -la .planning/phases/07-multi-platform-testing/07-PLATFORM-CAPABILITY-MATRIX.md

# 4. Check if Phase 7.1 needed
cat .planning/phases/07-multi-platform-testing/07-ANALYSIS-REPORT.md | grep "Needs Phase 7.1"

# 5. If Phase 7.1 needed, verify discovery document
cat .planning/phases/07.1-fix-platform-issues/07.1-DISCOVERY.md

# 6. Review metrics
echo "Installation rate:"
cat .planning/phases/07-multi-platform-testing/07-ANALYSIS-REPORT.md | grep "Installation success rate"
echo "Regression rate:"
cat .planning/phases/07-multi-platform-testing/07-ANALYSIS-REPORT.md | grep "Regression pass rate"
```

## Success Criteria

- [x] scripts/analyze-test-results.js analyzes all test result files
- [x] Analysis script calculates key metrics (install rate, regression rate, failure counts)
- [x] Analysis script categorizes failures by type and severity
- [x] scripts/generate-platform-matrix.js creates capability matrix
- [x] Platform capability matrix documents features/tools per platform (PLAT-11)
- [x] 07-ANALYSIS-REPORT.md generated with detailed findings
- [x] 07-VALIDATION-REPORT.md template created with executive summary structure
- [x] 07-PLATFORM-CAPABILITY-MATRIX.md documents platform support
- [x] Phase 7.1 directory and discovery template created (conditional)
- [x] Clear next steps documented based on P0/P1 failure counts
- [x] Decision point: Phase 7.1 required vs proceed to Phase 8

## Output

**Files created:**
- scripts/analyze-test-results.js (~350 lines) - Result analysis and metrics
- scripts/generate-platform-matrix.js (~250 lines) - Platform capability matrix generator
- .planning/phases/07-multi-platform-testing/07-ANALYSIS-REPORT.md - Raw data and findings
- .planning/phases/07-multi-platform-testing/07-VALIDATION-REPORT.md - Executive summary
- .planning/phases/07-multi-platform-testing/07-PLATFORM-CAPABILITY-MATRIX.md - Feature support matrix
- .planning/phases/07.1-fix-platform-issues/07.1-DISCOVERY.md - Gap closure template (conditional)

**Next:**
- **If P0 failures:** Execute Phase 7.1 gap closure (`/gsd-plan-phase 7.1`)
- **If only P1 or no failures:** Proceed to Phase 8 - Documentation & Release
