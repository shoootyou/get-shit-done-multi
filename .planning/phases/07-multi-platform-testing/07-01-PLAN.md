---
phase: 07-multi-platform-testing
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - test-environments/setup-test-env.js
  - test-environments/cleanup-test-env.js
  - test-environments/.gitignore
  - package.json
  - jest.config.js
  - __tests__/spec-parsing.test.js
  - __tests__/conditional-rendering.test.js
  - __tests__/frontmatter-validation.test.js
  - __tests__/metadata-generation.test.js
  - __tests__/platform-integration.test.js
autonomous: true
must_haves:
  - "Jest test suite with 5 spec validation tests runs successfully"
  - "Test environment setup script creates 3 isolated repo clones"
  - "Dependencies installed: jest, execa@5, strip-ansi, diff, p-map, tmp-promise, which"
  - "__tests__/ directory contains TEST-01 through TEST-05 coverage"
  - "jest.config.js configured for CommonJS project"
---

# Phase 7, Plan 1: Foundation + Jest Suite

**Objective:** Establish multi-platform test infrastructure with isolated environments and comprehensive Jest test suite for spec validation

## Context

Phase 7 tests all 29 GSD commands across 3 platforms (Claude Code, GitHub Copilot CLI, Codex CLI). This plan creates the foundation:
- Isolated test environments per platform (prevents cross-contamination)
- Jest test suite for spec validation (TEST-01 to TEST-05)
- Dependencies for process execution, output comparison, parallel testing

**From Phase 6:** Established 100% success rate standard with 69 passing orchestration tests. Phase 7 extends this to multi-platform coverage.

**From Context decisions:** Sequential platform testing (Copilot ‚Üí Claude ‚Üí Codex), isolated directories, hybrid automated/manual approach, test results in JSON format.

**From Research:** Keep existing native assert tests, add Jest for new coverage, use execa@5 (CommonJS compatible), JSON scenario format matches Phase 6 pattern.

## Tasks

<task name="setup-test-environments" type="auto">
  <files>
    test-environments/setup-test-env.js
    test-environments/cleanup-test-env.js
    test-environments/.gitignore
  </files>
  
  <action>
Create test-environments/ directory structure for isolated platform testing.

**1. Create setup-test-env.js script:**

```javascript
#!/usr/bin/env node
const { execSync } = require('child_process');
const fs = require('fs');
const path = require('path');

const platforms = ['copilot', 'claude', 'codex'];
const testRoot = path.join(__dirname);

async function setupEnvironment(platform) {
  console.log(`\nüì¶ Setting up ${platform} test environment...`);
  
  const platformDir = path.join(testRoot, `${platform}-test`);
  const repoDir = path.join(platformDir, 'get-shit-done');
  
  // Clean existing
  if (fs.existsSync(platformDir)) {
    console.log(`  üßπ Cleaning existing ${platform}-test/...`);
    fs.rmSync(platformDir, { recursive: true, force: true });
  }
  
  // Create directory
  fs.mkdirSync(platformDir, { recursive: true });
  
  // Clone repo (from parent directory)
  const parentRepo = path.resolve(__dirname, '..');
  console.log(`  üîÑ Cloning repo to ${platform}-test/get-shit-done/...`);
  execSync(`git clone ${parentRepo} ${repoDir}`, {
    cwd: platformDir,
    stdio: 'inherit'
  });
  
  // Install dependencies
  console.log(`  üì• Installing dependencies in ${platform}-test/...`);
  execSync('npm install', {
    cwd: repoDir,
    stdio: 'inherit'
  });
  
  console.log(`  ‚úÖ ${platform} environment ready`);
  
  return { platformDir, repoDir };
}

async function main() {
  console.log('üöÄ Setting up multi-platform test environments\n');
  console.log(`Test root: ${testRoot}\n`);
  
  for (const platform of platforms) {
    await setupEnvironment(platform);
  }
  
  console.log('\n‚úÖ All test environments ready!');
  console.log('\nNext steps:');
  console.log('  1. Run platform installation: node scripts/test-platform-install.js');
  console.log('  2. Test commands: node scripts/test-platform-commands.js');
}

if (require.main === module) {
  main().catch(err => {
    console.error('‚ùå Setup failed:', err.message);
    process.exit(1);
  });
}

module.exports = { setupEnvironment };
```

**2. Create cleanup-test-env.js script:**

```javascript
#!/usr/bin/env node
const fs = require('fs');
const path = require('path');

const platforms = ['copilot', 'claude', 'codex'];
const testRoot = path.join(__dirname);

function cleanup() {
  console.log('üßπ Cleaning up test environments...\n');
  
  for (const platform of platforms) {
    const platformDir = path.join(testRoot, `${platform}-test`);
    
    if (fs.existsSync(platformDir)) {
      console.log(`  üóëÔ∏è  Removing ${platform}-test/...`);
      fs.rmSync(platformDir, { recursive: true, force: true });
      console.log(`  ‚úÖ ${platform}-test removed`);
    } else {
      console.log(`  ‚è≠Ô∏è  ${platform}-test doesn't exist, skipping`);
    }
  }
  
  console.log('\n‚úÖ Cleanup complete!');
}

if (require.main === module) {
  cleanup();
}

module.exports = { cleanup };
```

**3. Create .gitignore:**

```
# Test environment directories (never commit)
copilot-test/
claude-test/
codex-test/

# Test results
test-results.json
test-results.yml
*.test-output.txt
```

**4. Make scripts executable:**

```bash
chmod +x test-environments/setup-test-env.js
chmod +x test-environments/cleanup-test-env.js
```
  </action>
  
  <verify>
```bash
# Verify scripts exist and are executable
ls -la test-environments/setup-test-env.js
ls -la test-environments/cleanup-test-env.js
cat test-environments/.gitignore

# Test setup script (dry run - will clone repos)
node test-environments/setup-test-env.js

# Verify 3 environments created
ls -d test-environments/copilot-test/get-shit-done
ls -d test-environments/claude-test/get-shit-done
ls -d test-environments/codex-test/get-shit-done

# Test cleanup
node test-environments/cleanup-test-env.js
ls test-environments/  # Should only show scripts and .gitignore
```
  </verify>
  
  <done>
- [x] test-environments/setup-test-env.js creates 3 isolated repo clones
- [x] test-environments/cleanup-test-env.js removes all test directories
- [x] test-environments/.gitignore prevents committing test artifacts
- [x] Scripts are executable and can run independently
  </done>
</task>

<task name="add-jest-dependencies" type="auto">
  <files>
    package.json
    jest.config.js
  </files>
  
  <action>
Install Jest and testing dependencies, configure for CommonJS project.

**1. Install dependencies:**

```bash
npm install --save-dev \
  jest@29.x \
  execa@5.1.1 \
  strip-ansi@7.x \
  diff@5.x \
  p-map@4.x \
  tmp-promise@3.x \
  which@3.x
```

Note: Using execa@5.1.1 (not @9.x) for CommonJS compatibility. Project uses `"type": "commonjs"` in package.json.

**2. Create jest.config.js:**

```javascript
module.exports = {
  // Test environment
  testEnvironment: 'node',
  
  // Test match patterns
  testMatch: [
    '**/__tests__/**/*.test.js',
    '**/?(*.)+(spec|test).js'
  ],
  
  // Coverage configuration
  collectCoverageFrom: [
    'bin/**/*.js',
    'specs/**/*.js',
    '!bin/**/*.test.js',
    '!bin/lib/orchestration/test-scenarios/**',
    '!**/node_modules/**'
  ],
  
  // Coverage thresholds (start low, increase over time)
  coverageThreshold: {
    global: {
      statements: 0,
      branches: 0,
      functions: 0,
      lines: 0
    }
  },
  
  // Timeout for async tests
  testTimeout: 30000,
  
  // Clear mocks between tests
  clearMocks: true,
  
  // Verbose output
  verbose: true,
  
  // Transform (none needed for CommonJS)
  transform: {},
  
  // Module file extensions
  moduleFileExtensions: ['js', 'json', 'node']
};
```

**3. Add test scripts to package.json:**

Add to "scripts" section:
```json
"test": "jest",
"test:watch": "jest --watch",
"test:coverage": "jest --coverage",
"test:specs": "jest __tests__/",
"test:orchestration": "node bin/lib/orchestration/orchestration-test-suite.js"
```

**4. Create __tests__/ directory:**

```bash
mkdir -p __tests__
```
  </action>
  
  <verify>
```bash
# Verify dependencies installed
npm list jest execa strip-ansi diff p-map tmp-promise which

# Verify jest.config.js exists
cat jest.config.js

# Verify test scripts added
npm run | grep test

# Verify Jest runs (no tests yet, but should initialize)
npx jest --version
npx jest --listTests  # Should list any .test.js files found
```
  </verify>
  
  <done>
- [x] Dependencies installed: jest@29, execa@5.1.1, strip-ansi, diff, p-map, tmp-promise, which
- [x] jest.config.js configured for Node.js CommonJS environment
- [x] Test scripts added to package.json (test, test:watch, test:coverage)
- [x] __tests__/ directory created for new spec tests
  </done>
</task>

<task name="create-jest-spec-tests" type="auto">
  <files>
    __tests__/spec-parsing.test.js
    __tests__/conditional-rendering.test.js
    __tests__/frontmatter-validation.test.js
    __tests__/metadata-generation.test.js
    __tests__/platform-integration.test.js
  </files>
  
  <action>
Create comprehensive Jest test suite for spec validation (TEST-01 to TEST-05).

**1. Create spec-parsing.test.js (TEST-01):**

```javascript
const fs = require('fs').promises;
const path = require('path');
const yaml = require('yaml');

describe('Spec Parsing (TEST-01)', () => {
  const specsDir = path.join(__dirname, '..', 'specs', 'skills');
  
  test('All spec files parse as valid YAML', async () => {
    const specDirs = await fs.readdir(specsDir);
    const skillDirs = specDirs.filter(d => d.startsWith('gsd-'));
    
    expect(skillDirs.length).toBeGreaterThan(0);
    
    for (const dir of skillDirs) {
      const skillFile = path.join(specsDir, dir, 'SKILL.md');
      
      if (await fileExists(skillFile)) {
        const content = await fs.readFile(skillFile, 'utf8');
        const frontmatter = extractFrontmatter(content);
        
        // Should parse without throwing
        expect(() => yaml.parse(frontmatter)).not.toThrow();
        
        const parsed = yaml.parse(frontmatter);
        expect(parsed).toBeDefined();
        expect(typeof parsed).toBe('object');
      }
    }
  });
  
  test('All specs have required frontmatter fields', async () => {
    const specDirs = await fs.readdir(specsDir);
    const skillDirs = specDirs.filter(d => d.startsWith('gsd-'));
    
    const required = ['name', 'description', 'tools'];
    
    for (const dir of skillDirs) {
      const skillFile = path.join(specsDir, dir, 'SKILL.md');
      
      if (await fileExists(skillFile)) {
        const content = await fs.readFile(skillFile, 'utf8');
        const frontmatter = extractFrontmatter(content);
        const parsed = yaml.parse(frontmatter);
        
        for (const field of required) {
          expect(parsed).toHaveProperty(field);
          expect(parsed[field]).toBeDefined();
        }
      }
    }
  });
  
  test('Spec folder names match skill names', async () => {
    const specDirs = await fs.readdir(specsDir);
    const skillDirs = specDirs.filter(d => d.startsWith('gsd-'));
    
    for (const dir of skillDirs) {
      const skillFile = path.join(specsDir, dir, 'SKILL.md');
      
      if (await fileExists(skillFile)) {
        const content = await fs.readFile(skillFile, 'utf8');
        const frontmatter = extractFrontmatter(content);
        const parsed = yaml.parse(frontmatter);
        
        expect(parsed.name).toBe(dir);
      }
    }
  });
});

// Helper functions
async function fileExists(filePath) {
  try {
    await fs.access(filePath);
    return true;
  } catch {
    return false;
  }
}

function extractFrontmatter(content) {
  const match = content.match(/^---\n([\s\S]*?)\n---/);
  return match ? match[1] : '';
}
```

**2. Create conditional-rendering.test.js (TEST-02):**

```javascript
const { generateAgent } = require('../bin/lib/template-system/generateAgent');
const fs = require('fs').promises;
const path = require('path');
const yaml = require('yaml');

describe('Conditional Rendering (TEST-02)', () => {
  const platforms = ['claude', 'copilot', 'codex'];
  
  test('Platform conditionals render correctly', async () => {
    // Test with sample spec containing conditionals
    const testSpec = {
      name: 'test-conditional',
      description: 'Test conditional rendering',
      tools: ['view', 'edit'],
      body: `
{{#isClaude}}
Claude-specific content
{{/isClaude}}
{{#isCopilot}}
Copilot-specific content
{{/isCopilot}}
{{#isCodex}}
Codex-specific content
{{/isCodex}}
      `.trim()
    };
    
    for (const platform of platforms) {
      const rendered = generateAgent(testSpec, platform);
      
      // Each platform should only see its own content
      if (platform === 'claude') {
        expect(rendered).toContain('Claude-specific content');
        expect(rendered).not.toContain('Copilot-specific content');
        expect(rendered).not.toContain('Codex-specific content');
      } else if (platform === 'copilot') {
        expect(rendered).not.toContain('Claude-specific content');
        expect(rendered).toContain('Copilot-specific content');
        expect(rendered).not.toContain('Codex-specific content');
      } else if (platform === 'codex') {
        expect(rendered).not.toContain('Claude-specific content');
        expect(rendered).not.toContain('Copilot-specific content');
        expect(rendered).toContain('Codex-specific content');
      }
    }
  });
  
  test('Tools array renders without conditionals', () => {
    const testSpec = {
      name: 'test-tools',
      description: 'Test tool rendering',
      tools: ['view', 'edit', 'bash', 'create'],
      body: 'Test content'
    };
    
    for (const platform of platforms) {
      const rendered = generateAgent(testSpec, platform);
      
      // Tools should be present for all platforms
      expect(rendered).toContain('view');
      expect(rendered).toContain('edit');
      expect(rendered).toContain('bash');
      expect(rendered).toContain('create');
    }
  });
});
```

**3. Create frontmatter-validation.test.js (TEST-03):**

```javascript
const fs = require('fs').promises;
const path = require('path');
const yaml = require('yaml');

describe('Frontmatter Validation (TEST-03)', () => {
  const specsDir = path.join(__dirname, '..', 'specs', 'skills');
  
  test('All specs have valid name format', async () => {
    const specs = await loadAllSpecs();
    
    for (const spec of specs) {
      // Name should be gsd-something
      expect(spec.name).toMatch(/^gsd-[a-z0-9-]+$/);
    }
  });
  
  test('All specs have non-empty descriptions', async () => {
    const specs = await loadAllSpecs();
    
    for (const spec of specs) {
      expect(spec.description).toBeDefined();
      expect(typeof spec.description).toBe('string');
      expect(spec.description.length).toBeGreaterThan(10);
    }
  });
  
  test('Tools are arrays of strings', async () => {
    const specs = await loadAllSpecs();
    
    for (const spec of specs) {
      expect(Array.isArray(spec.tools)).toBe(true);
      
      for (const tool of spec.tools) {
        expect(typeof tool).toBe('string');
      }
    }
  });
  
  test('No invalid frontmatter fields', async () => {
    const specs = await loadAllSpecs();
    const validFields = [
      'name', 'description', 'tools', 'metadata',
      'version', 'author', 'platform', 'tags'
    ];
    
    for (const spec of specs) {
      const fields = Object.keys(spec);
      
      for (const field of fields) {
        // Skip if it's a valid field or body content
        if (validFields.includes(field) || field === 'body') {
          continue;
        }
        
        // Warn about unexpected fields (not fail - may be extensions)
        console.warn(`Unexpected field in ${spec.name}: ${field}`);
      }
    }
  });
});

async function loadAllSpecs() {
  const specsDir = path.join(__dirname, '..', 'specs', 'skills');
  const specDirs = await fs.readdir(specsDir);
  const skillDirs = specDirs.filter(d => d.startsWith('gsd-'));
  
  const specs = [];
  
  for (const dir of skillDirs) {
    const skillFile = path.join(specsDir, dir, 'SKILL.md');
    
    try {
      const content = await fs.readFile(skillFile, 'utf8');
      const frontmatter = extractFrontmatter(content);
      const parsed = yaml.parse(frontmatter);
      
      specs.push(parsed);
    } catch (err) {
      // Skip invalid specs
      console.warn(`Failed to load ${dir}: ${err.message}`);
    }
  }
  
  return specs;
}

function extractFrontmatter(content) {
  const match = content.match(/^---\n([\s\S]*?)\n---/);
  return match ? match[1] : '';
}
```

**4. Create metadata-generation.test.js (TEST-04):**

```javascript
const { generateAgent } = require('../bin/lib/template-system/generateAgent');

describe('Metadata Generation (TEST-04)', () => {
  test('Generated timestamp is recent', () => {
    const testSpec = {
      name: 'test-metadata',
      description: 'Test metadata generation',
      tools: ['view'],
      body: 'Test content'
    };
    
    const rendered = generateAgent(testSpec, 'claude');
    
    // Should contain generated timestamp
    expect(rendered).toMatch(/generated.*\d{4}-\d{2}-\d{2}/);
    
    // Extract and verify timestamp is recent (within last 5 minutes)
    const timestampMatch = rendered.match(/generated.*(\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2})/);
    if (timestampMatch) {
      const generated = new Date(timestampMatch[1]);
      const now = new Date();
      const diffMinutes = (now - generated) / (1000 * 60);
      
      expect(diffMinutes).toBeLessThan(5);
    }
  });
  
  test('Version number is included', () => {
    const testSpec = {
      name: 'test-version',
      description: 'Test version inclusion',
      tools: ['view'],
      body: 'Test content'
    };
    
    const rendered = generateAgent(testSpec, 'claude');
    
    // Should contain version (semantic versioning pattern)
    expect(rendered).toMatch(/version.*\d+\.\d+\.\d+/);
  });
  
  test('Platform field is correct', () => {
    const testSpec = {
      name: 'test-platform',
      description: 'Test platform field',
      tools: ['view'],
      body: 'Test content'
    };
    
    const platforms = ['claude', 'copilot', 'codex'];
    
    for (const platform of platforms) {
      const rendered = generateAgent(testSpec, platform);
      
      // Should contain correct platform name
      expect(rendered).toContain(`platform: ${platform}`);
    }
  });
});
```

**5. Create platform-integration.test.js (TEST-05):**

```javascript
const { generateSkillsFromSpecs } = require('../bin/lib/generateSkillsFromSpecs');
const fs = require('fs').promises;
const path = require('path');

describe('Platform Integration (TEST-05)', () => {
  test('generateSkillsFromSpecs processes all platforms', async () => {
    const stats = await generateSkillsFromSpecs();
    
    expect(stats).toBeDefined();
    expect(stats.claude).toBeDefined();
    expect(stats.copilot).toBeDefined();
    expect(stats.codex).toBeDefined();
    
    // Should have generated skills for each platform
    expect(stats.claude.generated).toBeGreaterThan(0);
    expect(stats.copilot.generated).toBeGreaterThan(0);
    expect(stats.codex.generated).toBeGreaterThan(0);
  });
  
  test('Shared frontmatter is loaded and merged', async () => {
    const sharedPath = path.join(__dirname, '..', 'specs', 'skills', '_shared.yml');
    
    const exists = await fileExists(sharedPath);
    expect(exists).toBe(true);
    
    if (exists) {
      const content = await fs.readFile(sharedPath, 'utf8');
      expect(content.length).toBeGreaterThan(0);
      
      // Should contain common fields
      expect(content).toMatch(/description|tools|metadata/);
    }
  });
  
  test('Platform-specific directories are correct', () => {
    const expectedDirs = {
      claude: '.claude/get-shit-done',
      copilot: '.github/copilot/skills',
      codex: '.codex/skills'
    };
    
    for (const [platform, dir] of Object.entries(expectedDirs)) {
      // Test that path is correctly constructed (actual dir may not exist yet)
      const fullPath = path.join(__dirname, '..', dir);
      expect(fullPath).toContain(dir);
    }
  });
});

async function fileExists(filePath) {
  try {
    await fs.access(filePath);
    return true;
  } catch {
    return false;
  }
}
```
  </action>
  
  <verify>
```bash
# Run Jest test suite
npm test

# Should see:
# - 5 test suites (one per file)
# - Multiple tests per suite
# - All tests passing or with clear failure messages

# Run specific test
npm test -- spec-parsing.test.js

# Verify test files exist
ls -la __tests__/*.test.js
```
  </verify>
  
  <done>
- [x] __tests__/spec-parsing.test.js validates YAML parsing and structure (TEST-01)
- [x] __tests__/conditional-rendering.test.js validates platform conditionals (TEST-02)
- [x] __tests__/frontmatter-validation.test.js validates required fields (TEST-03)
- [x] __tests__/metadata-generation.test.js validates auto-generated metadata (TEST-04)
- [x] __tests__/platform-integration.test.js validates cross-platform generation (TEST-05)
- [x] All tests pass or provide actionable failure messages
  </done>
</task>

## Verification

```bash
# 1. Verify test environment setup
node test-environments/setup-test-env.js
ls -la test-environments/*/get-shit-done

# 2. Verify dependencies installed
npm list jest execa strip-ansi diff p-map

# 3. Run Jest test suite
npm test

# 4. Check Jest configuration
npx jest --showConfig
```

## Success Criteria

- [x] test-environments/setup-test-env.js creates 3 isolated repo clones (copilot-test, claude-test, codex-test)
- [x] test-environments/cleanup-test-env.js removes all test artifacts
- [x] Dependencies installed: jest@29, execa@5.1.1, strip-ansi@7, diff@5, p-map@4, tmp-promise@3, which@3
- [x] jest.config.js configured for CommonJS, 30s timeout, verbose output
- [x] 5 Jest test files created covering TEST-01 through TEST-05
- [x] Jest test suite runs and reports results (pass/fail/pending)
- [x] Test scripts added to package.json (test, test:watch, test:coverage)

## Output

**Files created:**
- test-environments/setup-test-env.js (139 lines)
- test-environments/cleanup-test-env.js (37 lines)
- test-environments/.gitignore (10 lines)
- jest.config.js (45 lines)
- __tests__/spec-parsing.test.js (~100 lines)
- __tests__/conditional-rendering.test.js (~80 lines)
- __tests__/frontmatter-validation.test.js (~90 lines)
- __tests__/metadata-generation.test.js (~70 lines)
- __tests__/platform-integration.test.js (~70 lines)

**Files modified:**
- package.json (added devDependencies and test scripts)

**Next:** Plan 2 creates platform testing scripts and executes cross-platform verification
