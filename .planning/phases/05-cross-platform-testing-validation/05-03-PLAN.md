---
phase: 05-cross-platform-testing-validation
plan: 03
type: execute
wave: 3
depends_on: [05-01, 05-02]
files_modified:
  - bin/test-cross-platform.js
  - docs/TESTING-CROSS-PLATFORM.md
  - package.json
autonomous: true
must_haves:
  - "Running `npm test` executes all cross-platform tests in sequence"
  - "E2E runner orchestrates: generation â†’ installation â†’ invocation â†’ report"
  - "Test results clearly show pass/fail for each validation stage"
  - "Documentation explains how to run tests locally"
  - "npm test script added to package.json for convenience"
---

# Objective

Create unified test runner that orchestrates all validation stages and documentation for the cross-platform testing workflow.

## Context

**What Exists:**
- Generation tests (Plan 1) - `bin/test-agent-generation.js`
- Installation tests (Plan 1) - `bin/test-agent-installation.js`
- Invocation tests (Plan 2) - `bin/test-agent-invocation.js`
- Custom test framework pattern

**What's Needed:**
- Unified runner that executes all tests in sequence
- Clear reporting of results across all stages
- Documentation for running tests
- npm script integration

**Phase Goal:** Complete end-to-end validation workflow.

## Tasks

<task name="create-e2e-runner" type="auto">
  <files>bin/test-cross-platform.js</files>
  <action>
Create unified test runner that orchestrates all validation stages.

**Runner Structure:**
```javascript
#!/usr/bin/env node

const { spawn } = require('child_process');
const path = require('path');

/**
 * Execute test script and capture result
 * @param {string} scriptPath - Path to test script
 * @param {string} name - Test suite name
 * @returns {Promise<Object>} - { success, duration, output }
 */
function runTestSuite(scriptPath, name) {
  return new Promise((resolve) => {
    const startTime = Date.now();
    console.log(`\n${'='.repeat(60)}`);
    console.log(`Running: ${name}`);
    console.log('='.repeat(60));
    
    const proc = spawn('node', [scriptPath], {
      stdio: 'inherit',
      cwd: path.dirname(scriptPath)
    });
    
    proc.on('close', (exitCode) => {
      const duration = Date.now() - startTime;
      const success = exitCode === 0;
      
      resolve({ success, duration, exitCode });
    });
    
    proc.on('error', (err) => {
      console.error(`Failed to run ${name}: ${err.message}`);
      resolve({ success: false, duration: 0, exitCode: 1, error: err.message });
    });
  });
}

async function main() {
  console.log(`
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                           â•‘
â•‘   Cross-Platform Testing & Validation Suite              â•‘
â•‘                                                           â•‘
â•‘   Validates template â†’ agent â†’ install â†’ invoke           â•‘
â•‘                                                           â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
`);
  
  const suites = [
    {
      name: 'Agent Generation Tests',
      script: path.join(__dirname, 'test-agent-generation.js'),
      description: 'Validates all 11 agents generate correctly for both platforms'
    },
    {
      name: 'Agent Installation Tests',
      script: path.join(__dirname, 'test-agent-installation.js'),
      description: 'Validates installation to correct platform directories'
    },
    {
      name: 'Agent Invocation Tests',
      script: path.join(__dirname, 'test-agent-invocation.js'),
      description: 'Validates agents respond via CLI (requires CLI installation)'
    }
  ];
  
  const results = [];
  let totalDuration = 0;
  
  for (const suite of suites) {
    console.log(`\nğŸ“‹ ${suite.description}`);
    
    const result = await runTestSuite(suite.script, suite.name);
    results.push({ ...suite, ...result });
    totalDuration += result.duration;
  }
  
  // Summary
  console.log(`\n\n${'='.repeat(60)}`);
  console.log('TEST SUMMARY');
  console.log('='.repeat(60));
  
  for (const result of results) {
    const status = result.success ? 'âœ… PASS' : 'âŒ FAIL';
    const duration = `${(result.duration / 1000).toFixed(2)}s`;
    console.log(`${status} - ${result.name} (${duration})`);
  }
  
  console.log('='.repeat(60));
  
  const totalPassed = results.filter(r => r.success).length;
  const totalFailed = results.filter(r => !r.success).length;
  
  console.log(`\nTotal: ${results.length} suites`);
  console.log(`âœ… Passed: ${totalPassed}`);
  console.log(`âŒ Failed: ${totalFailed}`);
  console.log(`â±ï¸  Duration: ${(totalDuration / 1000).toFixed(2)}s`);
  
  if (totalFailed > 0) {
    console.log(`\nâš ï¸  ${totalFailed} test suite(s) failed`);
    console.log('Review output above for details.\n');
    process.exit(1);
  } else {
    console.log('\nğŸ‰ All cross-platform tests passed!\n');
    process.exit(0);
  }
}

if (require.main === module) {
  main().catch(err => {
    console.error('Fatal error:', err);
    process.exit(1);
  });
}

module.exports = { main };
```

**Features:**
- Sequential test execution
- Clear stage-by-stage output
- Duration tracking per suite
- Summary with pass/fail counts
- Proper exit codes for CI integration

**Exit Codes:**
- 0 if all suites pass
- 1 if any suite fails
  </action>
  <verify>
```bash
node bin/test-cross-platform.js
# Should run all 3 test suites
# Exit 0 if all pass
```
  </verify>
  <done>
E2E runner exists, orchestrates all test suites, provides clear summary reporting.
  </done>
</task>

<task name="add-npm-test-script" type="auto">
  <files>package.json</files>
  <action>
Add `test` script to package.json for convenient test execution.

**Update package.json:**

Find the `"scripts"` section and add:

```json
"scripts": {
  "test": "node bin/test-cross-platform.js",
  "test:generation": "node bin/test-agent-generation.js",
  "test:installation": "node bin/test-agent-installation.js",
  "test:invocation": "node bin/test-agent-invocation.js",
  ...existing scripts...
}
```

This allows:
- `npm test` - Run all tests
- `npm run test:generation` - Run only generation tests
- `npm run test:installation` - Run only installation tests
- `npm run test:invocation` - Run only invocation tests
  </action>
  <verify>
```bash
npm test
# Should run bin/test-cross-platform.js

npm run test:generation
# Should run bin/test-agent-generation.js
```
  </verify>
  <done>
package.json has test scripts, npm test runs E2E suite, individual scripts available.
  </done>
</task>

<task name="create-testing-documentation" type="auto">
  <files>docs/TESTING-CROSS-PLATFORM.md</files>
  <action>
Create documentation for cross-platform testing workflow.

**Documentation Content:**

```markdown
# Cross-Platform Testing & Validation

This document explains the cross-platform testing suite that validates the template system generates working agents for both Claude and Copilot platforms.

## Overview

The test suite validates the complete pipeline:

```
Agent Spec â†’ Template Engine â†’ Generated Agent â†’ Installation â†’ Invocation
```

**Test Stages:**

1. **Generation** - Validates agents generate correctly for both platforms
2. **Installation** - Validates files land in correct platform directories
3. **Invocation** - Validates agents respond via CLI (smoke tests)

## Prerequisites

**Required:**
- Node.js installed
- Project dependencies installed (`npm install`)

**Optional (for invocation tests):**
- Claude CLI installed (`claude --version` works)
- GitHub Copilot CLI installed (`gh copilot --version` works)
- Agents installed via `node bin/install.js --all`

## Running Tests

### All Tests (Recommended)

```bash
npm test
```

Runs all test suites in sequence:
1. Agent Generation Tests (22 tests - 11 agents Ã— 2 platforms)
2. Agent Installation Tests (5 tests)
3. Agent Invocation Tests (depends on CLI availability)

### Individual Test Suites

**Generation Only:**
```bash
npm run test:generation
```

Validates:
- All 11 agents generate for Claude
- All 11 agents generate for Copilot
- Frontmatter structure compliance
- Platform-specific formatting

**Installation Only:**
```bash
npm run test:installation
```

Validates:
- Files install to correct directories
- Platform-specific formatting (tools string vs array)
- Metadata presence (Copilot only)

**Invocation Only:**
```bash
npm run test:invocation
```

Validates:
- Agents respond via CLI
- Tool execution works
- Platform-specific features

**Note:** Invocation tests require actual CLI installations. Tests skip gracefully if CLIs not available.

## Test Output

### Successful Run

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                           â•‘
â•‘   Cross-Platform Testing & Validation Suite              â•‘
â•‘                                                           â•‘
â•‘   Validates template â†’ agent â†’ install â†’ invoke           â•‘
â•‘                                                           â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

============================================================
Running: Agent Generation Tests
============================================================

=== Agent Generation Tests ===

Platform: claude

âœ… gsd-executor: Generated successfully
âœ… gsd-planner: Generated successfully
...

Platform: copilot

âœ… gsd-executor: Generated successfully
âœ… gsd-planner: Generated successfully
...

============================================================
Total agents tested: 22 (11 agents Ã— 2 platforms)
âœ… Passed: 22
âŒ Failed: 0
============================================================

============================================================
Running: Agent Installation Tests
============================================================

=== Agent Installation Tests ===

Test 1: Claude local installation

âœ… Claude: Agent installed to .claude/agents/

Test 2: Copilot installation

âœ… Copilot: Agent installed to .github/copilot/agents/

...

============================================================
âœ… Passed: 5
âŒ Failed: 0
============================================================

============================================================
Running: Agent Invocation Tests
============================================================

=== Agent Invocation Smoke Tests ===

Claude CLI: âœ… Available
Copilot CLI: âœ… Available

--- Claude CLI Tests ---

Testing: gsd-executor
  âœ… Agent responded (exit 0)
  âœ… Tools used in response
  Duration: 2500ms

...

============================================================
âœ… Passed: 6
âŒ Failed: 0
âš ï¸  Skipped: 2
============================================================

============================================================
TEST SUMMARY
============================================================
âœ… PASS - Agent Generation Tests (3.45s)
âœ… PASS - Agent Installation Tests (1.23s)
âœ… PASS - Agent Invocation Tests (8.76s)
============================================================

Total: 3 suites
âœ… Passed: 3
âŒ Failed: 0
â±ï¸  Duration: 13.44s

ğŸ‰ All cross-platform tests passed!
```

### Failed Test

If tests fail, output shows:

```
âŒ FAIL - Agent Generation Tests (2.34s)

âš ï¸  1 test suite(s) failed
Review output above for details.
```

Exit code: 1 (for CI integration)

## Test Architecture

### Test Framework

Custom Node.js test runner (zero npm dependencies):

- Console-based output (âœ…/âŒ emojis)
- Explicit assertions
- Exit code reporting (0 = pass, 1 = fail)
- Temp file cleanup

### Test Files

```
bin/
â”œâ”€â”€ test-cross-platform.js         # E2E orchestrator
â”œâ”€â”€ test-agent-generation.js       # Generation validation
â”œâ”€â”€ test-agent-installation.js     # Installation validation
â”œâ”€â”€ test-agent-invocation.js       # Invocation smoke tests
â””â”€â”€ lib/test-helpers/
    â””â”€â”€ cli-invoker.js             # CLI process spawning helper
```

### Test Data

- **Generation:** Uses real agent specs from `agents/*.md`
- **Installation:** Uses temp directories (`/tmp/agent-*-test-{timestamp}`)
- **Invocation:** Uses simple prompts ("List files", "What is your role?")

All tests clean up temp files after execution.

## Platform-Specific Validation

### Claude

- Tools formatted as comma-separated string: `tools: read, write, bash`
- No metadata field
- Local installation: `.claude/agents/`
- Global installation: `~/.claude/agents/`

### Copilot

- Tools formatted as array: `tools: [search, execute, edit]`
- Metadata field required
- Installation: `.github/copilot/agents/`

## Troubleshooting

### Generation Tests Fail

**Issue:** "Template rendering failed"

**Solution:**
- Check agent spec frontmatter is valid YAML
- Verify template engine is working: `node -e "require('./bin/lib/template-system/generator')"`

### Installation Tests Fail

**Issue:** "Files not in expected location"

**Solution:**
- Check adapters exist: `ls bin/lib/adapters/`
- Verify adapters export required functions

### Invocation Tests Skip

**Issue:** "No CLIs available"

**Solution:**
- Install Claude CLI: https://docs.anthropic.com/claude-cli
- Install Copilot CLI: `gh extension install github/gh-copilot`
- Verify: `claude --version` and `gh copilot --version`

### Invocation Tests Fail

**Issue:** "Agent not found"

**Solution:**
- Install agents: `node bin/install.js --all`
- Verify installation: `ls .claude/agents/` or `ls .github/copilot/agents/`

**Issue:** "Invocation timeout"

**Solution:**
- Check CLI is responding: `claude agent gsd-executor "hello"`
- Increase timeout in test file (default: 30s)

## CI Integration

Tests are designed for local development (cannot run on GitHub Actions - no CLI access).

For CI integration of generation/installation tests only:

```yaml
- name: Run generation tests
  run: npm run test:generation

- name: Run installation tests
  run: npm run test:installation
```

Invocation tests should be run manually by developers.

## Adding New Tests

### New Agent

No changes needed - generation/installation tests discover agents automatically from `agents/*.md`.

### New Platform

1. Add adapter to `bin/lib/adapters/{platform}.js`
2. Update `bin/test-agent-generation.js` platforms array
3. Update `bin/test-agent-installation.js` with platform-specific validation
4. Add invocation method to `bin/lib/test-helpers/cli-invoker.js`
5. Update `bin/test-agent-invocation.js` with platform tests

## Maintenance

### Test Coverage

Current coverage:
- **Generation:** 11 agents Ã— 2 platforms = 22 tests
- **Installation:** 5 tests (paths, formatting, metadata)
- **Invocation:** 2 agents Ã— 2 platforms = 4+ tests (depends on CLI availability)

### Test Philosophy

- **Smoke tests, not exhaustive:** Quick validation that things work
- **Focus on integration:** Template â†’ agent â†’ install â†’ invoke
- **Graceful degradation:** Skip tests if dependencies unavailable
- **Fast execution:** All tests complete in < 30 seconds (excluding invocation)

---

*Last updated: Phase 5 (Cross-Platform Testing & Validation)*
```
  </action>
  <verify>
```bash
# Verify documentation exists and is readable
cat docs/TESTING-CROSS-PLATFORM.md | head -50
```
  </verify>
  <done>
Documentation exists, explains testing workflow, troubleshooting, architecture, and usage.
  </done>
</task>

## Verification

**Success Criteria:**
- [ ] `bin/test-cross-platform.js` exists and runs
- [ ] E2E runner executes all 3 test suites in sequence
- [ ] Test summary shows clear pass/fail for each suite
- [ ] `npm test` script added to package.json
- [ ] Individual test scripts available (test:generation, etc.)
- [ ] `docs/TESTING-CROSS-PLATFORM.md` exists
- [ ] Documentation explains how to run tests, troubleshoot issues

**Commands:**
```bash
# Run all tests
npm test

# Run individual test suites
npm run test:generation
npm run test:installation
npm run test:invocation

# Check documentation
cat docs/TESTING-CROSS-PLATFORM.md
```

## Success Criteria

Phase 5 Plan 3 complete when:
- E2E runner orchestrates all test stages
- npm test provides convenient test execution
- Test summary clearly reports pass/fail
- Documentation explains testing workflow
- Developers can run full validation suite locally

## Output

Files created:
- `bin/test-cross-platform.js` - Unified test orchestrator
- `docs/TESTING-CROSS-PLATFORM.md` - Testing documentation

Files modified:
- `package.json` - Added test scripts

Complete test suite:
- Generation tests (22 tests)
- Installation tests (5 tests)
- Invocation tests (4+ tests, CLI-dependent)
- E2E orchestration
