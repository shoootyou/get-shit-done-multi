---
phase: 02-platform-abstraction-layer
plan: 03
type: execute
wave: 2
depends_on: ["02-01", "02-02"]
files_modified:
  - bin/lib/template-system/generator.js
  - bin/lib/template-system/validators.js
  - bin/lib/template-system/validators.test.js
  - bin/lib/template-system/integration.test.js
autonomous: true

must_haves:
  truths:
    - "Generator integrates tool mapper for platform-specific tool names"
    - "Generator uses field transformer for platform-specific metadata"
    - "Generated Claude agents validate against Claude spec requirements"
    - "Generated Copilot agents validate against Copilot spec requirements"
    - "Platform-specific validation catches unsupported fields"
    - "Integration tests verify platform abstraction works end-to-end"
  artifacts:
    - path: "bin/lib/template-system/validators.js"
      provides: "Platform-specific YAML frontmatter validators"
      exports: ["validateClaudeSpec", "validateCopilotSpec"]
      min_lines: 120
    - path: "bin/lib/template-system/generator.js"
      provides: "Enhanced generator with platform abstraction (updated)"
      contains: "tool-mapper.*field-transformer"
      min_lines: 420
  key_links:
    - from: "generator.js"
      to: "tool-mapper.js"
      via: "mapTools() call in pipeline"
      pattern: "require.*tool-mapper.*mapTools"
    - from: "generator.js"
      to: "field-transformer.js"
      via: "transformFields() call in pipeline"
      pattern: "require.*field-transformer.*transformFields"
    - from: "validators.js"
      to: "REQUIREMENTS.md"
      via: "PLAT-01, PLAT-02 compliance checks"
      pattern: "validateClaudeSpec.*validateCopilotSpec"
---

<objective>
Integrate platform abstraction (tool mapper + field transformer) into generator pipeline and add platform-specific validators to ensure generated agents comply with Claude and Copilot specifications.

Purpose: Complete platform abstraction layer so generator produces valid, optimized agents for each platform using research-backed transformation rules.
Output: Enhanced generator with integrated abstractions, platform validators, and comprehensive integration tests proving end-to-end platform handling.
</objective>

<execution_context>
@.github/skills/get-shit-done/get-shit-done/workflows/execute-plan.md
@.github/skills/get-shit-done/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/REQUIREMENTS.md
@.planning/research/PITFALLS.md
@.planning/phases/01-template-engine-foundation/01-03-SUMMARY.md
@.planning/phases/02-platform-abstraction-layer/02-01-PLAN.md
@.planning/phases/02-platform-abstraction-layer/02-02-PLAN.md
@bin/lib/template-system/generator.js
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create platform-specific validators</name>
  <files>bin/lib/template-system/validators.js, bin/lib/template-system/validators.test.js</files>
  <action>
    Create validators.js implementing platform-specific frontmatter validation based on official specs:
    
    1. validateClaudeSpec(frontmatter) function:
       
       Required fields:
       - name (string, non-empty)
       - description (string, non-empty)
       
       Optional but validated fields:
       - tools (array of strings, proper case: 'Bash' not 'bash')
       - model (string, one of: 'sonnet', 'haiku', 'opus')
       - hooks (object, valid lifecycle keys)
       - skills (array of strings)
       - color (string)
       - disallowedTools (array of strings)
       
       Validation rules:
       - Tool names are case-sensitive (check exact case matches canonical names)
       - No tools: ['*'] wildcard syntax (error if found)
       - Hooks must have valid keys (on_create, on_message, etc.)
       - Model must be valid value if present
       
       Return: { valid: boolean, errors: [], warnings: [] }
    
    2. validateCopilotSpec(frontmatter) function:
       
       Required fields:
       - name (string, non-empty)
       - description (string, non-empty)
       
       Optional but validated fields:
       - tools (array of strings or "*" for all)
       - mcp-servers (object, if org/enterprise)
       - color (string)
       
       Validation rules:
       - tools: ["*"] is valid (unlike Claude)
       - Warn if model field present (ignored on Copilot - Pitfall 3)
       - Warn if hooks field present (not supported - Pitfall 10)
       - Warn if skills field present (not supported - Pitfall 10)
       - Warn if disallowedTools present (not supported - Pitfall 4)
       - MCP config structure validated if present
       
       Return: { valid: boolean, errors: [], warnings: [] }
    
    3. validateSpec(frontmatter, platform) function:
       - Dispatcher to appropriate platform validator
       - Returns unified validation result
    
    4. checkPromptLength(promptText, platform) function:
       - Verify prompt doesn't exceed platform limits
       - Claude: 200,000 chars
       - Copilot: 30,000 chars (Pitfall 7)
       - Return warning if approaching limit (>90%)
    
    Create validators.test.js with:
    - Valid Claude spec passes validation
    - Invalid Claude spec (lowercase tools) fails
    - Valid Copilot spec passes validation
    - Copilot spec with model field generates warning (not error)
    - Copilot spec with hooks generates warning
    - tools: ["*"] valid on Copilot, invalid on Claude
    - Prompt length validation for both platforms
    - Edge cases: missing fields, null values, unknown platforms
    
    Target: 15-18 validator tests
  </action>
  <verify>
    node bin/lib/template-system/validators.test.js
    
    node -e "
    const v = require('./bin/lib/template-system/validators');
    console.log('Claude valid:', v.validateClaudeSpec({name: 'test', description: 'test', tools: ['Bash']}));
    console.log('Claude invalid:', v.validateClaudeSpec({name: 'test', description: 'test', tools: ['bash']}));
    console.log('Copilot with model:', v.validateCopilotSpec({name: 'test', description: 'test', model: 'haiku'}));
    "
    
    Should show:
    - Claude valid spec passes
    - Claude lowercase tools fail
    - Copilot model field warns but doesn't fail
  </verify>
  <done>
    - validateClaudeSpec() enforces Claude-specific rules (case-sensitive tools, no wildcards)
    - validateCopilotSpec() enforces Copilot-specific rules (allows wildcards, warns on unsupported fields)
    - checkPromptLength() validates against platform limits
    - 15+ validator tests passing
    - Validation errors are descriptive and actionable
    - Warnings distinguish between errors (blocking) and warnings (informational)
  </done>
</task>

<task type="auto">
  <name>Task 2: Integrate platform abstraction into generator pipeline</name>
  <files>bin/lib/template-system/generator.js</files>
  <action>
    Update generator.js (from Phase 1 Plan 03) to integrate tool-mapper and field-transformer:
    
    1. Import new modules at top:
       ```javascript
       const toolMapper = require('./tool-mapper');
       const fieldTransformer = require('./field-transformer');
       const validators = require('./validators');
       ```
    
    2. Update generateAgent() pipeline to include platform abstraction:
       
       Current pipeline: parse → context → render → validate
       
       Enhanced pipeline: parse → context → **transform-tools** → render → **transform-fields** → validate → **validate-platform**
       
       Specifically:
       a) After context building, before rendering:
          - If frontmatter.tools exists, call toolMapper.mapTools(frontmatter.tools, platform)
          - Replace tools array with platform-specific tool names
          - Store tool warnings in result.warnings
       
       b) After rendering, before YAML validation:
          - Call fieldTransformer.transformFields(renderedFrontmatter, platform)
          - Remove/transform platform-specific fields
          - Add generation metadata with fieldTransformer.addPlatformMetadata()
          - Store field warnings in result.warnings
       
       c) After YAML validation:
          - Call validators.validateSpec(finalFrontmatter, platform)
          - Add platform-specific validation errors/warnings to result
       
       d) Check prompt length:
          - Extract full prompt text (frontmatter + body)
          - Call validators.checkPromptLength(prompt, platform)
          - Warn if approaching platform limit
    
    3. Update result object structure:
       ```javascript
       {
         success: boolean,
         output: string,
         errors: [],
         warnings: [
           { stage: 'tool-mapping', message: '...' },
           { stage: 'field-transform', message: '...' },
           { stage: 'platform-validation', message: '...' }
         ],
         metadata: {
           platform: string,
           toolsTransformed: boolean,
           fieldsTransformed: boolean,
           validationPassed: boolean
         }
       }
       ```
    
    4. Maintain backward compatibility:
       - All Phase 1 integration tests should still pass
       - Existing generateAgent() API unchanged (same signature)
       - Options (validateOnly, dryRun) still work
    
    5. Update JSDoc comments to document new pipeline stages
  </action>
  <verify>
    # Run Phase 1 integration tests (should still pass)
    node bin/lib/template-system/integration.test.js
    
    # Test new platform abstraction
    node -e "
    const fs = require('fs');
    const gen = require('./bin/lib/template-system/generator');
    
    // Create test spec with platform-specific features
    const spec = \`---
name: test-agent
description: Test agent
tools: ['Bash', 'Read', 'Edit']
model: haiku
hooks:
  on_create: echo test
---
Test agent body with {{platform}} variable.
\`;
    
    fs.writeFileSync('/tmp/test-platform-spec.md', spec);
    
    // Generate for both platforms
    const claude = gen.generateAgent('/tmp/test-platform-spec.md', 'claude');
    const copilot = gen.generateAgent('/tmp/test-platform-spec.md', 'copilot');
    
    console.log('Claude success:', claude.success);
    console.log('Claude has model:', claude.output.includes('model: haiku'));
    console.log('Claude has hooks:', claude.output.includes('hooks:'));
    
    console.log('Copilot success:', copilot.success);
    console.log('Copilot has model:', copilot.output.includes('model:'));
    console.log('Copilot warnings:', copilot.warnings.length > 0);
    "
    
    Should show:
    - Both platforms generate successfully
    - Claude includes model and hooks
    - Copilot excludes model/hooks with warnings
  </verify>
  <done>
    - Generator imports tool-mapper, field-transformer, validators modules
    - Pipeline enhanced with 3 new stages (tool mapping, field transformation, platform validation)
    - Tool names transformed to platform-specific format
    - Fields transformed per platform support
    - Generation metadata added to output
    - Result object includes warnings array with stage context
    - All Phase 1 integration tests still pass (backward compatible)
    - New platform-specific transformations work correctly
  </done>
</task>

<task type="auto">
  <name>Task 3: Add comprehensive platform abstraction integration tests</name>
  <files>bin/lib/template-system/integration.test.js</files>
  <action>
    Update integration.test.js (from Phase 1 Plan 03) with new platform abstraction tests:
    
    Add 8 new integration tests:
    
    1. Platform-specific tool transformation:
       - Spec with ['Bash', 'Read', 'Edit'] generates correctly for both platforms
       - Tool names preserve case for Claude
       - Verify tools array in output matches platform expectations
    
    2. Model field handling:
       - Spec with model: 'haiku' includes field in Claude output
       - Same spec excludes model field in Copilot output
       - Copilot result includes warning about ignored model field
    
    3. Hooks handling:
       - Spec with hooks generates correctly for Claude
       - Same spec excludes hooks for Copilot with warning
    
    4. Platform-specific tool warnings:
       - Spec with WebFetch tool warns when generating for Copilot
       - Spec with canonical tools (Bash, Read, Edit) has no warnings
    
    5. Tool wildcard handling:
       - Spec with tools: ["*"] fails validation for Claude
       - Same spec passes for Copilot
    
    6. Field validation integration:
       - Spec with lowercase tools ('bash') fails Claude validation
       - Error message identifies exact issue (case sensitivity)
    
    7. Prompt length validation:
       - Spec with very long prompt (>30k chars) warns for Copilot
       - Same prompt is fine for Claude (200k limit)
    
    8. End-to-end platform abstraction:
       - Complex spec with multiple platform-specific features
       - Generates valid output for both platforms
       - Claude includes: model, hooks, case-sensitive tools
       - Copilot excludes: model, hooks; includes warnings
       - Both outputs validate successfully
    
    Keep all 8 existing Phase 1 integration tests.
    New total: 16 integration tests (8 Phase 1 + 8 Phase 2)
  </action>
  <verify>
    node bin/lib/template-system/integration.test.js
    
    Should show:
    - 16 integration tests passing
    - 8 Phase 1 tests still pass (backward compatibility)
    - 8 Phase 2 tests pass (platform abstraction)
    - Platform-specific transformations verified end-to-end
  </verify>
  <done>
    - 8 new platform abstraction integration tests added
    - All 8 Phase 1 tests still pass (backward compatible)
    - Total: 16 integration tests passing
    - Platform-specific tool transformation verified
    - Field transformation verified (model, hooks handling)
    - Tool wildcard handling verified
    - Prompt length validation verified
    - End-to-end platform abstraction proven functional
  </done>
</task>

</tasks>

<verification>
Run complete template system test suite:

```bash
# All unit tests
node bin/lib/template-system/spec-parser.test.js          # 8 tests (Phase 1)
node bin/lib/template-system/context-builder.test.js      # 17-19 tests (Phase 1 + 2)
node bin/lib/template-system/engine.test.js               # 17 tests (Phase 1)
node bin/lib/template-system/tool-mapper.test.js          # 12-15 tests (Phase 2)
node bin/lib/template-system/field-transformer.test.js    # 15-18 tests (Phase 2)
node bin/lib/template-system/validators.test.js           # 15-18 tests (Phase 2)

# Integration tests
node bin/lib/template-system/integration.test.js          # 16 tests (8 Phase 1 + 8 Phase 2)

# Manual verification
node -e "
const gen = require('./bin/lib/template-system/generator');
const spec = require('fs').readFileSync('agents/gsd-planner.md', 'utf8');
const tmpPath = '/tmp/test-agent.md';
require('fs').writeFileSync(tmpPath, spec);

console.log('=== Testing Platform Abstraction ===');
const claude = gen.generateAgent(tmpPath, 'claude');
const copilot = gen.generateAgent(tmpPath, 'copilot');

console.log('Claude success:', claude.success);
console.log('Copilot success:', copilot.success);
console.log('Outputs differ:', claude.output !== copilot.output);
console.log('Platform abstraction working:', true);
"
```

Expected total: 84-95 tests passing across all modules.
</verification>

<success_criteria>
1. Generator integrates tool-mapper, field-transformer, validators successfully
2. Platform-specific tool names generated correctly (case-sensitive for Claude)
3. Field transformation removes unsupported fields (model on Copilot)
4. Platform validators catch spec violations (lowercase tools on Claude)
5. Integration tests prove end-to-end platform abstraction works
6. All Phase 1 tests still pass (backward compatibility maintained)
7. Warning system distinguishes errors from informational warnings
8. Generated agents validate against official Claude and Copilot specs (PLAT-01, PLAT-02)
9. Phase 2 complete: Platform abstraction layer fully functional
</success_criteria>

<output>
After completion, create `.planning/phases/02-platform-abstraction-layer/02-03-SUMMARY.md` documenting:
- Platform abstraction integration into generator
- Platform validators implementation
- End-to-end test results showing platform differences
- Phase 2 completion summary
- Ready for Phase 3 (spec migration and template generation)
</output>
