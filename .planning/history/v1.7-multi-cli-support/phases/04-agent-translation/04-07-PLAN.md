---
phase: 04-agent-translation
plan: 07
type: execute
wave: 3
depends_on: [04-05, 04-06]
files_modified:
  - bin/lib/orchestration/equivalence-test.js
  - bin/lib/orchestration/capability-matrix.js
  - docs/agent-capabilities.md
autonomous: true
gap_closure: true

must_haves:
  truths:
    - "Equivalence tests run with real adapters instead of mocks"
    - "Cross-CLI agent output comparison works end-to-end"
    - "Capability matrix reflects actual adapter implementation status"
    - "Documentation accurately represents current agent capabilities"
  artifacts:
    - path: "bin/lib/orchestration/equivalence-test.js"
      provides: "Real CLI equivalence testing"
      min_lines: 235
    - path: "bin/lib/orchestration/capability-matrix.js"
      provides: "Updated capability matrix"
      min_lines: 165
    - path: "docs/agent-capabilities.md"
      provides: "Regenerated capability documentation"
      min_lines: 130
  key_links:
    - from: "equivalence-test.js"
      to: "agent-invoker.js with real adapters"
      via: "invokeAgent calls"
      pattern: "invokeAgent.*agent.*prompt"
---

<objective>
Enable equivalence testing with real adapters and update capability matrix to reflect actual implementation status.

Purpose: Close verification gaps #3 and #4 by enabling cross-CLI comparison with real adapter execution and updating documentation to accurately reflect capabilities.

Output: Working equivalence tests that compare real agent outputs across CLIs, plus updated capability matrix showing actual support levels.
</objective>

<execution_context>
@.github/skills/get-shit-done/get-shit-done/workflows/execute-plan.md
@.github/skills/get-shit-done/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-agent-translation/04-VERIFICATION.md
@.planning/phases/04-agent-translation/04-01-SUMMARY.md
@.planning/phases/04-agent-translation/04-05-PLAN.md
@.planning/phases/04-agent-translation/04-06-PLAN.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Update equivalence tests to use real adapters</name>
  <files>bin/lib/orchestration/equivalence-test.js</files>
  <action>
Update equivalence-test.js to remove mock data assumptions and enable real CLI testing:

1. Add CLI availability check at start of runEquivalenceTests():
   ```javascript
   // Check which CLIs are available before testing
   const availableCLIs = [];
   try {
     await execFileAsync('claude-code', ['--version']);
     availableCLIs.push('claude');
   } catch (err) {
     console.warn('⚠️  Claude CLI not available, skipping Claude tests');
   }
   
   // Repeat for 'gh copilot' and 'codex'
   ```

2. Update test scenarios to skip unavailable CLIs:
   ```javascript
   // Only test available CLIs
   if (availableCLIs.length < 2) {
     console.warn('⚠️  Need at least 2 CLIs installed for equivalence testing');
     console.warn(`   Available: ${availableCLIs.join(', ')}`);
     return { success: false, reason: 'insufficient_clis' };
   }
   ```

3. Update testEquivalence() to handle real CLI errors:
   - Check result.success before comparing outputs
   - Log CLI stderr if invocation fails
   - Report partial success (some CLIs worked, others failed)

4. Add comment explaining test expectations:
   ```javascript
   // Equivalence testing with real CLIs:
   // - Success: Same agent on different CLIs produces semantically equivalent outputs
   // - Partial: Some CLIs succeed, others fail (CLI availability/config issues)
   // - Failure: Different outputs from same agent (indicates adapter bugs)
   ```

5. Remove hardcoded mock result checks - now checking actual CLI outputs

Key principles:
- Graceful degradation if CLIs unavailable
- Clear reporting of which CLIs were tested
- Distinguish between CLI availability issues vs actual equivalence failures
  </action>
  <verify>
```bash
# Check mock references removed
grep -n "Mock" bin/lib/orchestration/equivalence-test.js || echo "✅ No mock references"

# Check CLI availability logic added
grep -n "available" bin/lib/orchestration/equivalence-test.js && echo "✅ CLI checks present"

# Verify execFileAsync import
grep -n "execFileAsync" bin/lib/orchestration/equivalence-test.js && echo "✅ CLI execution support added"
```

Expect: No mock references, CLI availability checks present.
  </verify>
  <done>
equivalence-test.js updated to test real CLI invocations with graceful handling of unavailable CLIs.
  </done>
</task>

<task type="auto">
  <name>Task 2: Update capability matrix based on actual implementation</name>
  <files>bin/lib/orchestration/capability-matrix.js</files>
  <action>
Update AGENT_CAPABILITIES to reflect current reality:

Current state (from verification):
- Infrastructure: Complete (registry, invoker, performance tracking)
- Adapters: Real CLI execution implemented (04-05)
- Command integration: Working (04-06)
- Status: "Infrastructure ready, CLI execution implemented"

Update notes for each agent to reflect actual status:

```javascript
const AGENT_CAPABILITIES = {
  'gsd-executor': {
    claude: {
      level: 'full',
      notes: 'Real CLI execution via claude-code command (requires Claude CLI installed)'
    },
    copilot: {
      level: 'full',
      notes: 'Real CLI execution via gh copilot command (requires GitHub CLI + copilot extension)'
    },
    codex: {
      level: 'full',
      notes: 'Real CLI execution via codex skill command (requires Codex CLI installed)'
    }
  },
  // ... repeat for all 11 agents
};
```

Key updates:
1. Change notes from "full support" to "Real CLI execution via {command}"
2. Add "(requires {CLI} installed)" to set expectations
3. Keep level as 'full' since infrastructure is complete
4. Update generation timestamp

After updating, add comment block explaining status:
```javascript
/**
 * Capability Matrix Status (Phase 4 Gap Closure Complete):
 * 
 * ✅ Agent registry: All 11 agents registered
 * ✅ Agent invoker: CLI-agnostic invocation layer
 * ✅ Adapters: Real CLI command execution (not mocks)
 * ✅ Performance tracking: Sub-millisecond precision
 * ✅ Command integration: User-facing invoke-agent command
 * 
 * Level 'full' indicates infrastructure complete and CLI execution implemented.
 * Actual availability depends on CLI installation (claude-code, gh, codex).
 * Use /gsd:invoke-agent to test agent availability on your system.
 */
```
  </action>
  <verify>
```bash
# Check notes updated to mention CLI requirements
grep -n "requires.*CLI" bin/lib/orchestration/capability-matrix.js && echo "✅ CLI requirements documented"

# Check comment block added
grep -n "Capability Matrix Status" bin/lib/orchestration/capability-matrix.js && echo "✅ Status comment present"

# Verify all 11 agents still present
grep -c "gsd-" bin/lib/orchestration/capability-matrix.js
```

Expect: CLI requirements in notes, status comment present, 11 agents found.
  </verify>
  <done>
Capability matrix updated to reflect real CLI execution with clear documentation of requirements and current status.
  </done>
</task>

<task type="auto">
  <name>Task 3: Regenerate capability documentation</name>
  <files>docs/agent-capabilities.md</files>
  <action>
Regenerate docs/agent-capabilities.md using the updated capability matrix:

```bash
# Run documentation generator
node -e "
const { generateCapabilityDocs } = require('./bin/lib/orchestration/generate-capability-docs.js');
generateCapabilityDocs('./docs/agent-capabilities.md').then(() => {
  console.log('✅ Documentation regenerated');
}).catch(err => {
  console.error('❌ Generation failed:', err.message);
  process.exit(1);
});
"
```

Verify the regenerated documentation includes:
1. Updated notes mentioning CLI requirements
2. New generation timestamp
3. Status section explaining infrastructure readiness
4. All 11 agents with updated capability descriptions
5. CLI limitations section (unchanged)

After regeneration, add introductory paragraph to docs/agent-capabilities.md:

```markdown
## Phase 4 Status: Infrastructure Complete ✅

As of Phase 4 gap closure, the agent translation layer is **fully implemented**:

- ✅ All 11 GSD agents registered and available
- ✅ CLI-agnostic orchestration layer built
- ✅ Real CLI command execution (adapters no longer use mocks)
- ✅ Performance tracking with sub-millisecond precision
- ✅ User-facing `/gsd:invoke-agent` command for agent invocation

**Next steps:** Phase 5 (Testing & Verification) will validate cross-CLI equivalence and integration.

**Testing agent availability:** Run `/gsd:invoke-agent {agent-name} "{prompt}"` to test if an agent works on your installed CLI.

---
```

Insert this after the header, before the capability matrix table.
  </action>
  <verify>
```bash
# Check documentation regenerated with new timestamp
grep -n "Generated:" docs/agent-capabilities.md

# Check updated notes present
grep -n "requires.*CLI" docs/agent-capabilities.md && echo "✅ CLI requirements in docs"

# Check status section added
grep -n "Phase 4 Status" docs/agent-capabilities.md && echo "✅ Status section present"

# Verify all agents documented
grep -c "gsd-" docs/agent-capabilities.md
```

Expect: New timestamp, CLI requirements documented, status section present, 11 agents found.
  </verify>
  <done>
Documentation regenerated with updated capability matrix, CLI requirements, and Phase 4 completion status.
  </done>
</task>

</tasks>

<verification>
Comprehensive verification of gap closure:

```bash
echo "=== Gap #1: Adapter Stubs Removed ==="
grep -c "Mock agent execution" bin/lib/adapters/*.js
echo "Expect: 0 (no mocks remaining)"

echo ""
echo "=== Gap #2: Command Integration ==="
node bin/gsd-cli.js gsd:help | grep -i "invoke-agent"
echo "Expect: invoke-agent command listed"

echo ""
echo "=== Gap #3: Equivalence Testing Ready ==="
grep -n "availableCLIs" bin/lib/orchestration/equivalence-test.js
echo "Expect: CLI availability checks present"

echo ""
echo "=== Gap #4: Capability Matrix Updated ==="
grep -n "requires.*CLI" bin/lib/orchestration/capability-matrix.js
grep -n "Phase 4 Status" docs/agent-capabilities.md
echo "Expect: Updated notes and status documentation"

echo ""
echo "=== All Gaps Addressed ==="
echo "✅ Gap 1: Adapters use real CLI execution"
echo "✅ Gap 2: Agent invoker wired to commands"
echo "✅ Gap 3: Equivalence tests use real adapters"
echo "✅ Gap 4: Docs reflect actual capabilities"
```
</verification>

<success_criteria>
1. Equivalence tests updated to check CLI availability before testing
2. Tests handle real CLI execution failures gracefully
3. Capability matrix notes mention CLI installation requirements
4. Documentation regenerated with updated matrix and Phase 4 status
5. Status comment block explains infrastructure completion
6. All 11 agents documented with realistic capability descriptions
</success_criteria>

<output>
After completion, create `.planning/phases/04-agent-translation/04-07-SUMMARY.md` documenting:
- Equivalence test updates for real CLI execution
- Capability matrix accuracy improvements
- Documentation regeneration with Phase 4 status
- Comprehensive gap closure verification results
</output>
